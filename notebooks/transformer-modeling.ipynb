{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":3684057,"sourceType":"datasetVersion","datasetId":4021},{"sourceId":11536719,"sourceType":"datasetVersion","datasetId":7235302},{"sourceId":12140606,"sourceType":"datasetVersion","datasetId":7556281}],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import sys\nsys.path.append(\"/kaggle/input/utility-smart-meter/src\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:42:03.018466Z","iopub.execute_input":"2025-06-13T05:42:03.018837Z","iopub.status.idle":"2025-06-13T05:42:03.046617Z","shell.execute_reply.started":"2025-06-13T05:42:03.018817Z","shell.execute_reply":"2025-06-13T05:42:03.045912Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"pip install neuralforecast torch\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:42:04.153789Z","iopub.execute_input":"2025-06-13T05:42:04.154400Z","iopub.status.idle":"2025-06-13T05:42:09.109622Z","shell.execute_reply.started":"2025-06-13T05:42:04.154373Z","shell.execute_reply":"2025-06-13T05:42:09.108799Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Requirement already satisfied: neuralforecast in /usr/local/lib/python3.11/dist-packages (3.0.1)\nRequirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\nRequirement already satisfied: coreforecast>=0.0.6 in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (0.0.16)\nRequirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (2025.3.2)\nRequirement already satisfied: numpy>=1.21.6 in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (1.26.4)\nRequirement already satisfied: pandas>=1.3.5 in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (2.2.3)\nRequirement already satisfied: pytorch-lightning>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (2.5.1.post0)\nRequirement already satisfied: ray>=2.2.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.46.0)\nRequirement already satisfied: optuna in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (4.3.0)\nRequirement already satisfied: utilsforecast>=0.2.3 in /usr/local/lib/python3.11/dist-packages (from neuralforecast) (0.2.12)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\nRequirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy>=1.21.6->neuralforecast) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas>=1.3.5->neuralforecast) (2025.2)\nRequirement already satisfied: tqdm>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (4.67.1)\nRequirement already satisfied: PyYAML>=5.4 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (6.0.2)\nRequirement already satisfied: torchmetrics>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (1.7.1)\nRequirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (25.0)\nRequirement already satisfied: lightning-utilities>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from pytorch-lightning>=2.0.0->neuralforecast) (0.14.3)\nRequirement already satisfied: click>=7.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (8.1.8)\nRequirement already satisfied: jsonschema in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (4.23.0)\nRequirement already satisfied: msgpack<2.0.0,>=1.0.0 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (1.1.0)\nRequirement already satisfied: protobuf!=3.19.5,>=3.15.3 in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.20.3)\nRequirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2.32.3)\nRequirement already satisfied: tensorboardX>=1.9 in /usr/local/lib/python3.11/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (2.6.4)\nRequirement already satisfied: pyarrow>=9.0.0 in /usr/local/lib/python3.11/dist-packages (from ray[tune]>=2.2.0->neuralforecast) (19.0.1)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\nRequirement already satisfied: alembic>=1.5.0 in /usr/local/lib/python3.11/dist-packages (from optuna->neuralforecast) (1.15.2)\nRequirement already satisfied: colorlog in /usr/local/lib/python3.11/dist-packages (from optuna->neuralforecast) (6.9.0)\nRequirement already satisfied: sqlalchemy>=1.4.2 in /usr/local/lib/python3.11/dist-packages (from optuna->neuralforecast) (2.0.40)\nRequirement already satisfied: Mako in /usr/local/lib/python3.11/dist-packages (from alembic>=1.5.0->optuna->neuralforecast) (1.3.10)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (3.11.18)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.10.0->pytorch-lightning>=2.0.0->neuralforecast) (75.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas>=1.3.5->neuralforecast) (1.17.0)\nRequirement already satisfied: greenlet>=1 in /usr/local/lib/python3.11/dist-packages (from sqlalchemy>=1.4.2->optuna->neuralforecast) (3.1.1)\nRequirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (25.3.0)\nRequirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2024.10.1)\nRequirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.36.2)\nRequirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.11/dist-packages (from jsonschema->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (0.24.0)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->neuralforecast) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy>=1.21.6->neuralforecast) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy>=1.21.6->neuralforecast) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy>=1.21.6->neuralforecast) (2024.2.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.4.2)\nRequirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (3.10)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2.4.0)\nRequirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->ray>=2.2.0->ray[tune]>=2.2.0->neuralforecast) (2025.4.26)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.3.2)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]>=2022.5.0->pytorch-lightning>=2.0.0->neuralforecast) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy>=1.21.6->neuralforecast) (2024.2.0)\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"code","source":"# Core libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\n\n# Project-specific modules\nfrom data.data_loader import load_all_raw_data\nfrom data.data_cleaner import clean_and_merge_all_data\nfrom features.feature_pipeline import create_comprehensive_features\nfrom features.splitters import prepare_forecasting_data  # for train/val/test splits\nfrom utils.helpers import reduce_memory_footprint\nfrom utils.sequence_builder import build_global_sequences  # optional, use only if needed\n\n# Evaluation helpers (ensure they’re model-agnostic)\nfrom evaluation.forecast_evaluation import (\n    compute_forecast_metrics,\n    print_split_summary,\n    evaluate_model,\n    evaluate_peak_performance,\n    evaluate_forecast_residuals\n)\n\nfrom visualization.forecast_plots import (\n    plot_feature_importance,\n    plot_actual_vs_predicted,\n    plot_peak_actual_vs_predicted\n)\n\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import PatchTST\nfrom neuralforecast.losses.pytorch import MSE\n\n# Scikit-learn for generic evaluation\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\n# Encoding (only if needed for categorical features)\nfrom sklearn.preprocessing import LabelEncoder\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:42:09.110997Z","iopub.execute_input":"2025-06-13T05:42:09.111245Z","iopub.status.idle":"2025-06-13T05:42:26.010452Z","shell.execute_reply.started":"2025-06-13T05:42:09.111212Z","shell.execute_reply":"2025-06-13T05:42:26.009707Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"# Set the base path where all your data files and folders are located\ndata_path = \"/kaggle/input/smart-meters-in-london\"\n\n# Call the function to load all raw datasets: consumption, household, weather, and holiday data\nraw_data = load_all_raw_data(data_path)\n\n# Extract each dataset from the returned dictionary for easier access\ndf_consumption = raw_data[\"consumption\"]  # Half-hourly electricity consumption records\ndf_household = raw_data[\"household\"]      # Household metadata (e.g., tariff, ACORN group)\ndf_weather = raw_data[\"weather\"]          # Daily weather data\ndf_holiday = raw_data[\"holiday\"]          # UK bank holiday dates\n\n# Display the first few rows of the consumption data to confirm successful loading\ndf_consumption.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:42:26.011589Z","iopub.execute_input":"2025-06-13T05:42:26.011819Z","iopub.status.idle":"2025-06-13T05:43:05.000152Z","shell.execute_reply.started":"2025-06-13T05:42:26.011801Z","shell.execute_reply":"2025-06-13T05:43:04.999522Z"}},"outputs":[{"name":"stdout","text":"🚀 LOADING ALL RAW DATA\n==============================\n📂 Found 112 consumption files\n✅ Loaded 3,469,352 consumption records\n📂 Loading household data...\n✅ Loaded 5,566 households\n📂 Loading weather data...\n✅ Loaded 882 weather records\n📂 Loading holiday data...\n✅ Loaded 25 holiday records\n🎉 ALL RAW DATA LOADED\n","output_type":"stream"},{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"       LCLid        day   hh_0   hh_1   hh_2   hh_3   hh_4   hh_5   hh_6  \\\n0  MAC000047 2011-12-09  0.114  0.074  0.107  0.098  0.090  0.106  0.077   \n1  MAC000047 2011-12-10  0.035  0.082  0.050  0.064  0.059  0.048  0.082   \n2  MAC000047 2011-12-11  0.103  0.085  0.083  0.113  0.072  0.096  0.098   \n3  MAC000047 2011-12-12  0.107  0.072  0.109  0.088  0.099  0.098  0.075   \n4  MAC000047 2011-12-13  0.073  0.108  0.084  0.101  0.095  0.078  0.118   \n\n    hh_7  ...  hh_38  hh_39  hh_40  hh_41  hh_42  hh_43  hh_44  hh_45  hh_46  \\\n0  0.115  ...  0.097  0.134  0.295  0.063  0.072  0.040  0.074  0.051  0.065   \n1  0.044  ...  0.120  0.115  0.106  0.135  0.077  0.104  0.096  0.076  0.106   \n2  0.084  ...  0.191  0.163  0.203  0.182  0.168  0.145  0.074  0.114  0.078   \n3  0.120  ...  0.160  0.195  0.156  0.105  0.125  0.076  0.111  0.074  0.098   \n4  0.080  ...  0.181  0.130  0.146  0.116  0.113  0.110  0.082  0.120  0.079   \n\n   hh_47  \n0  0.068  \n1  0.076  \n2  0.096  \n3  0.104  \n4  0.101  \n\n[5 rows x 50 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LCLid</th>\n      <th>day</th>\n      <th>hh_0</th>\n      <th>hh_1</th>\n      <th>hh_2</th>\n      <th>hh_3</th>\n      <th>hh_4</th>\n      <th>hh_5</th>\n      <th>hh_6</th>\n      <th>hh_7</th>\n      <th>...</th>\n      <th>hh_38</th>\n      <th>hh_39</th>\n      <th>hh_40</th>\n      <th>hh_41</th>\n      <th>hh_42</th>\n      <th>hh_43</th>\n      <th>hh_44</th>\n      <th>hh_45</th>\n      <th>hh_46</th>\n      <th>hh_47</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MAC000047</td>\n      <td>2011-12-09</td>\n      <td>0.114</td>\n      <td>0.074</td>\n      <td>0.107</td>\n      <td>0.098</td>\n      <td>0.090</td>\n      <td>0.106</td>\n      <td>0.077</td>\n      <td>0.115</td>\n      <td>...</td>\n      <td>0.097</td>\n      <td>0.134</td>\n      <td>0.295</td>\n      <td>0.063</td>\n      <td>0.072</td>\n      <td>0.040</td>\n      <td>0.074</td>\n      <td>0.051</td>\n      <td>0.065</td>\n      <td>0.068</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MAC000047</td>\n      <td>2011-12-10</td>\n      <td>0.035</td>\n      <td>0.082</td>\n      <td>0.050</td>\n      <td>0.064</td>\n      <td>0.059</td>\n      <td>0.048</td>\n      <td>0.082</td>\n      <td>0.044</td>\n      <td>...</td>\n      <td>0.120</td>\n      <td>0.115</td>\n      <td>0.106</td>\n      <td>0.135</td>\n      <td>0.077</td>\n      <td>0.104</td>\n      <td>0.096</td>\n      <td>0.076</td>\n      <td>0.106</td>\n      <td>0.076</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MAC000047</td>\n      <td>2011-12-11</td>\n      <td>0.103</td>\n      <td>0.085</td>\n      <td>0.083</td>\n      <td>0.113</td>\n      <td>0.072</td>\n      <td>0.096</td>\n      <td>0.098</td>\n      <td>0.084</td>\n      <td>...</td>\n      <td>0.191</td>\n      <td>0.163</td>\n      <td>0.203</td>\n      <td>0.182</td>\n      <td>0.168</td>\n      <td>0.145</td>\n      <td>0.074</td>\n      <td>0.114</td>\n      <td>0.078</td>\n      <td>0.096</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MAC000047</td>\n      <td>2011-12-12</td>\n      <td>0.107</td>\n      <td>0.072</td>\n      <td>0.109</td>\n      <td>0.088</td>\n      <td>0.099</td>\n      <td>0.098</td>\n      <td>0.075</td>\n      <td>0.120</td>\n      <td>...</td>\n      <td>0.160</td>\n      <td>0.195</td>\n      <td>0.156</td>\n      <td>0.105</td>\n      <td>0.125</td>\n      <td>0.076</td>\n      <td>0.111</td>\n      <td>0.074</td>\n      <td>0.098</td>\n      <td>0.104</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MAC000047</td>\n      <td>2011-12-13</td>\n      <td>0.073</td>\n      <td>0.108</td>\n      <td>0.084</td>\n      <td>0.101</td>\n      <td>0.095</td>\n      <td>0.078</td>\n      <td>0.118</td>\n      <td>0.080</td>\n      <td>...</td>\n      <td>0.181</td>\n      <td>0.130</td>\n      <td>0.146</td>\n      <td>0.116</td>\n      <td>0.113</td>\n      <td>0.110</td>\n      <td>0.082</td>\n      <td>0.120</td>\n      <td>0.079</td>\n      <td>0.101</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 50 columns</p>\n</div>"},"metadata":{}}],"execution_count":4},{"cell_type":"code","source":"# Clean and merge all raw data\ndf_final = clean_and_merge_all_data(raw_data)\n\n# View the final cleaned and enriched dataset\ndf_final.head()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:43:05.000918Z","iopub.execute_input":"2025-06-13T05:43:05.001242Z","iopub.status.idle":"2025-06-13T05:43:26.317911Z","shell.execute_reply.started":"2025-06-13T05:43:05.001213Z","shell.execute_reply":"2025-06-13T05:43:26.317237Z"}},"outputs":[{"name":"stdout","text":"🚀 CLEANING AND MERGING ALL DATA\n========================================\n🧹 Cleaning consumption data...\n   ✅ Removed 0 rows with >20.0% missing\n   ✅ Kept 5,556 households with ≥30 days\n   🔧 Interpolating missing values...\n✅ Consumption data cleaned: (3469317, 50)\n🏠 Preparing household data...\n✅ Household data prepared: (5566, 4)\n🌤️ Preparing weather data...\n   ⚠️ Found 3 dates with multiple records (likely DST transitions):\n   📝 Duplicate dates: [Timestamp('2014-03-30 00:00:00'), Timestamp('2013-03-31 00:00:00'), Timestamp('2012-03-25 00:00:00')]\n   📊 Counts per duplicate date:\nday\n2014-03-30    2\n2013-03-31    2\n2012-03-25    2\ndtype: int64\n   ✅ Removed 3 DST duplicate rows\n   📊 Weather data: 882 → 879 rows\n✅ Weather data prepared: (879, 6)\n🎉 Preparing holiday data...\n✅ Holiday data prepared: (25, 3)\n🔗 Merging all datasets...\n   ✅ After household merge: (3469317, 53)\n   ✅ After weather merge: (3469317, 58)\n   ✅ After holiday merge: (3469317, 59)\n✅ All data merged successfully\n📅 Adding basic temporal features...\n✅ Temporal features added\n🎉 FINAL CLEANED DATASET: (3469317, 61)\n","output_type":"stream"},{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"       LCLid        day   hh_0   hh_1   hh_2   hh_3   hh_4   hh_5   hh_6  \\\n0  MAC000047 2011-12-09  0.114  0.074  0.107  0.098  0.090  0.106  0.077   \n1  MAC000047 2011-12-10  0.035  0.082  0.050  0.064  0.059  0.048  0.082   \n2  MAC000047 2011-12-11  0.103  0.085  0.083  0.113  0.072  0.096  0.098   \n3  MAC000047 2011-12-12  0.107  0.072  0.109  0.088  0.099  0.098  0.075   \n4  MAC000047 2011-12-13  0.073  0.108  0.084  0.101  0.095  0.078  0.118   \n\n    hh_7  ...  Acorn_grouped  stdorToU  temperatureMax  temperatureMin  \\\n0  0.115  ...      Adversity       Std            7.68            2.03   \n1  0.044  ...      Adversity       Std            6.08           -0.13   \n2  0.084  ...      Adversity       Std            8.59            2.48   \n3  0.120  ...      Adversity       Std            9.82            3.09   \n4  0.080  ...      Adversity       Std           12.08            4.54   \n\n   humidity  windSpeed  cloudCover  holiday_category  month  season  \n0      0.71       5.65        0.15       Regular Day     12  Winter  \n1      0.81       3.08        0.17       Regular Day     12  Winter  \n2      0.88       3.94        0.56       Regular Day     12  Winter  \n3      0.84       5.02        0.38       Regular Day     12  Winter  \n4      0.75       7.44        0.42       Regular Day     12  Winter  \n\n[5 rows x 61 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>LCLid</th>\n      <th>day</th>\n      <th>hh_0</th>\n      <th>hh_1</th>\n      <th>hh_2</th>\n      <th>hh_3</th>\n      <th>hh_4</th>\n      <th>hh_5</th>\n      <th>hh_6</th>\n      <th>hh_7</th>\n      <th>...</th>\n      <th>Acorn_grouped</th>\n      <th>stdorToU</th>\n      <th>temperatureMax</th>\n      <th>temperatureMin</th>\n      <th>humidity</th>\n      <th>windSpeed</th>\n      <th>cloudCover</th>\n      <th>holiday_category</th>\n      <th>month</th>\n      <th>season</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>MAC000047</td>\n      <td>2011-12-09</td>\n      <td>0.114</td>\n      <td>0.074</td>\n      <td>0.107</td>\n      <td>0.098</td>\n      <td>0.090</td>\n      <td>0.106</td>\n      <td>0.077</td>\n      <td>0.115</td>\n      <td>...</td>\n      <td>Adversity</td>\n      <td>Std</td>\n      <td>7.68</td>\n      <td>2.03</td>\n      <td>0.71</td>\n      <td>5.65</td>\n      <td>0.15</td>\n      <td>Regular Day</td>\n      <td>12</td>\n      <td>Winter</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>MAC000047</td>\n      <td>2011-12-10</td>\n      <td>0.035</td>\n      <td>0.082</td>\n      <td>0.050</td>\n      <td>0.064</td>\n      <td>0.059</td>\n      <td>0.048</td>\n      <td>0.082</td>\n      <td>0.044</td>\n      <td>...</td>\n      <td>Adversity</td>\n      <td>Std</td>\n      <td>6.08</td>\n      <td>-0.13</td>\n      <td>0.81</td>\n      <td>3.08</td>\n      <td>0.17</td>\n      <td>Regular Day</td>\n      <td>12</td>\n      <td>Winter</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>MAC000047</td>\n      <td>2011-12-11</td>\n      <td>0.103</td>\n      <td>0.085</td>\n      <td>0.083</td>\n      <td>0.113</td>\n      <td>0.072</td>\n      <td>0.096</td>\n      <td>0.098</td>\n      <td>0.084</td>\n      <td>...</td>\n      <td>Adversity</td>\n      <td>Std</td>\n      <td>8.59</td>\n      <td>2.48</td>\n      <td>0.88</td>\n      <td>3.94</td>\n      <td>0.56</td>\n      <td>Regular Day</td>\n      <td>12</td>\n      <td>Winter</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MAC000047</td>\n      <td>2011-12-12</td>\n      <td>0.107</td>\n      <td>0.072</td>\n      <td>0.109</td>\n      <td>0.088</td>\n      <td>0.099</td>\n      <td>0.098</td>\n      <td>0.075</td>\n      <td>0.120</td>\n      <td>...</td>\n      <td>Adversity</td>\n      <td>Std</td>\n      <td>9.82</td>\n      <td>3.09</td>\n      <td>0.84</td>\n      <td>5.02</td>\n      <td>0.38</td>\n      <td>Regular Day</td>\n      <td>12</td>\n      <td>Winter</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>MAC000047</td>\n      <td>2011-12-13</td>\n      <td>0.073</td>\n      <td>0.108</td>\n      <td>0.084</td>\n      <td>0.101</td>\n      <td>0.095</td>\n      <td>0.078</td>\n      <td>0.118</td>\n      <td>0.080</td>\n      <td>...</td>\n      <td>Adversity</td>\n      <td>Std</td>\n      <td>12.08</td>\n      <td>4.54</td>\n      <td>0.75</td>\n      <td>7.44</td>\n      <td>0.42</td>\n      <td>Regular Day</td>\n      <td>12</td>\n      <td>Winter</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 61 columns</p>\n</div>"},"metadata":{}}],"execution_count":5},{"cell_type":"code","source":"# Run the full feature pipeline\ndf_features = create_comprehensive_features(df_final)\ndf_features['household_code'] = LabelEncoder().fit_transform(df_features['LCLid'])\n\n# Check the final DataFrame\ndf_features.head()\n\nprint(f\"✅ Feature engineering completed:\")\nprint(f\"   📊 Total samples: {len(df_features):,}\")\nprint(f\"   📅 Date range: {df_features['day'].min()} to {df_features['day'].max()}\")\nprint(f\"   🏠 Households: {df_features['LCLid'].nunique()}\")\nprint(f\"   🔧 Features created: {len(df_features.columns)} total columns\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:43:26.319486Z","iopub.execute_input":"2025-06-13T05:43:26.319770Z","iopub.status.idle":"2025-06-13T05:43:50.652792Z","shell.execute_reply.started":"2025-06-13T05:43:26.319751Z","shell.execute_reply":"2025-06-13T05:43:50.651946Z"}},"outputs":[{"name":"stdout","text":"🚀 CREATING COMPREHENSIVE FEATURES (all features retained)\n==================================================\n📅 Creating temporal features...\n🚀 Creating All Temporal Features\n===================================\n📅 Creating basic temporal features...\n   ✅ Created basic temporal features\n🌀 Creating seasonal features...\n   ✅ Created seasonal features\n🎉 Creating holiday features...\n   ✅ Created holiday features\n⚡ Creating peak period features...\n   ⚠️ peak_hour column not found\n📈 Creating time trend features...\n   ✅ Created time trend features\n✅ All temporal features created\n⚡ Creating consumption‐pattern features...\n⚡ Creating consumption features...\n   ✅ Created consumption features\n📊 Creating consumption patterns...\n   ✅ Created consumption patterns\n🌤️ Creating weather features...\n🚀 Creating All Weather Features\n===================================\n🌡️ Creating temperature features...\n   ✅ Created temperature features\n🌦️ Creating weather condition features...\n   ✅ Created weather condition features from ['humidity', 'windSpeed', 'cloudCover']\n🌡️ Creating temperature impact features...\n   ✅ Created temperature impact features\n🌨️ Creating seasonal weather features...\n   ✅ Created seasonal weather features\n✅ All weather features created\n📈 Creating time‐series features (lags and rolling windows)…\n🔗 Creating leakage‐safe interaction features...\n✅ FEATURE PIPELINE COMPLETE (all features retained)\n📊 Final shape: (3469317, 132)\n✅ Feature engineering completed:\n   📊 Total samples: 3,469,317\n   📅 Date range: 2011-11-24 00:00:00 to 2014-02-27 00:00:00\n   🏠 Households: 5556\n   🔧 Features created: 133 total columns\n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"import gc\ndel df_final\ngc.collect()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:43:50.653625Z","iopub.execute_input":"2025-06-13T05:43:50.653890Z","iopub.status.idle":"2025-06-13T05:43:50.955246Z","shell.execute_reply.started":"2025-06-13T05:43:50.653869Z","shell.execute_reply":"2025-06-13T05:43:50.954476Z"}},"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"64"},"metadata":{}}],"execution_count":7},{"cell_type":"code","source":"#df_features = reduce_memory_footprint(df_features)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Rename required columns\ndf_patchtst = df_features.rename(columns={\n    'LCLid': 'unique_id',\n    'day': 'ds',\n    'total_kwh': 'y'\n})\n\n# Define selected covariates\nexog_cols = [\n    # Temporal context\n    'dayofweek', 'month', 'is_weekend', 'is_holiday',\n    'month_sin', 'month_cos', 'dayofweek_sin', 'dayofweek_cos',\n    \n    # Season flags\n    'is_winter', 'is_summer', 'is_shoulder_season',\n\n    # Weather\n    'temperatureMax', 'temperatureMin', 'humidity',\n    'windSpeed', 'cloudCover',\n    'heating_degree_days', 'cooling_degree_days',\n    'is_very_cold', 'is_very_hot', 'is_high_humidity', 'is_windy',\n\n    # Load profile\n    'peak_kwh', 'mean_kwh', 'std_kwh',\n    'load_factor', 'daily_variability', 'coefficient_of_variation',\n    'usage_concentration', 'peak_sharpness', 'base_load', 'base_load_ratio',\n\n    # Lag & trend\n    'lag1_total', 'lag7_total', 'lag14_total',\n    'roll7_total_mean', 'roll14_total_mean',\n    'delta1_total', 'pct_change1_total',\n\n    # Leakage-safe interactions\n    'lag1_weekend_heating', 'lag1_holiday_consumption', 'lag1_summer_cooling'\n]\n\n# Build final dataset\ndf_patchtst = df_patchtst[['unique_id', 'ds', 'y'] + exog_cols].dropna()\ndf_patchtst = df_patchtst.sort_values(['unique_id', 'ds'])\n\nprint(\"✅ PatchTST-ready dataset shape:\", df_patchtst.shape)\ndf_patchtst.head()\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:12:21.215507Z","iopub.execute_input":"2025-06-12T23:12:21.216084Z","iopub.status.idle":"2025-06-12T23:12:31.511576Z","shell.execute_reply.started":"2025-06-12T23:12:21.216060Z","shell.execute_reply":"2025-06-12T23:12:31.510942Z"},"jupyter":{"source_hidden":true,"outputs_hidden":true},"collapsed":true},"outputs":[{"name":"stdout","text":"✅ PatchTST-ready dataset shape: (3366485, 45)\n","output_type":"stream"},{"execution_count":11,"output_type":"execute_result","data":{"text/plain":"       unique_id         ds       y  dayofweek  month  is_weekend  is_holiday  \\\n95710  MAC000002 2012-10-27  16.886          5     10           1           0   \n95712  MAC000002 2012-10-29  12.779          0     10           0           0   \n95713  MAC000002 2012-10-30  13.961          1     10           0           0   \n95714  MAC000002 2012-10-31  17.822          2     10           0           0   \n95715  MAC000002 2012-11-01  12.209          3     11           0           0   \n\n       month_sin  month_cos  dayofweek_sin  ...  lag1_total  lag7_total  \\\n95710  -0.866025   0.500000      -0.974928  ...      15.065      17.378   \n95712  -0.866025   0.500000       0.000000  ...      19.629      18.885   \n95713  -0.866025   0.500000       0.781831  ...      12.779      10.485   \n95714  -0.866025   0.500000       0.974928  ...      13.961      15.537   \n95715  -0.500000   0.866025       0.433884  ...      17.822      13.128   \n\n       lag14_total  roll7_total_mean  roll14_total_mean  delta1_total  \\\n95710       11.087         16.424000          13.526500         1.937   \n95712       10.257         15.659286          14.398286         2.743   \n95713        9.769         14.787000          14.578429        -6.850   \n95714       10.885         15.283571          14.877857         1.182   \n95715       10.751         15.610000          15.373357         3.861   \n\n       pct_change1_total  lag1_weekend_heating  lag1_holiday_consumption  \\\n95710           0.147547              9.699999                       0.0   \n95712           0.162442              0.000000                       0.0   \n95713          -0.348973              0.000000                       0.0   \n95714           0.092495              0.000000                       0.0   \n95715           0.276556              0.000000                       0.0   \n\n       lag1_summer_cooling  \n95710                  0.0  \n95712                  0.0  \n95713                  0.0  \n95714                  0.0  \n95715                  0.0  \n\n[5 rows x 45 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>unique_id</th>\n      <th>ds</th>\n      <th>y</th>\n      <th>dayofweek</th>\n      <th>month</th>\n      <th>is_weekend</th>\n      <th>is_holiday</th>\n      <th>month_sin</th>\n      <th>month_cos</th>\n      <th>dayofweek_sin</th>\n      <th>...</th>\n      <th>lag1_total</th>\n      <th>lag7_total</th>\n      <th>lag14_total</th>\n      <th>roll7_total_mean</th>\n      <th>roll14_total_mean</th>\n      <th>delta1_total</th>\n      <th>pct_change1_total</th>\n      <th>lag1_weekend_heating</th>\n      <th>lag1_holiday_consumption</th>\n      <th>lag1_summer_cooling</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>95710</th>\n      <td>MAC000002</td>\n      <td>2012-10-27</td>\n      <td>16.886</td>\n      <td>5</td>\n      <td>10</td>\n      <td>1</td>\n      <td>0</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>-0.974928</td>\n      <td>...</td>\n      <td>15.065</td>\n      <td>17.378</td>\n      <td>11.087</td>\n      <td>16.424000</td>\n      <td>13.526500</td>\n      <td>1.937</td>\n      <td>0.147547</td>\n      <td>9.699999</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95712</th>\n      <td>MAC000002</td>\n      <td>2012-10-29</td>\n      <td>12.779</td>\n      <td>0</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.000000</td>\n      <td>...</td>\n      <td>19.629</td>\n      <td>18.885</td>\n      <td>10.257</td>\n      <td>15.659286</td>\n      <td>14.398286</td>\n      <td>2.743</td>\n      <td>0.162442</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95713</th>\n      <td>MAC000002</td>\n      <td>2012-10-30</td>\n      <td>13.961</td>\n      <td>1</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.781831</td>\n      <td>...</td>\n      <td>12.779</td>\n      <td>10.485</td>\n      <td>9.769</td>\n      <td>14.787000</td>\n      <td>14.578429</td>\n      <td>-6.850</td>\n      <td>-0.348973</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95714</th>\n      <td>MAC000002</td>\n      <td>2012-10-31</td>\n      <td>17.822</td>\n      <td>2</td>\n      <td>10</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.866025</td>\n      <td>0.500000</td>\n      <td>0.974928</td>\n      <td>...</td>\n      <td>13.961</td>\n      <td>15.537</td>\n      <td>10.885</td>\n      <td>15.283571</td>\n      <td>14.877857</td>\n      <td>1.182</td>\n      <td>0.092495</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>95715</th>\n      <td>MAC000002</td>\n      <td>2012-11-01</td>\n      <td>12.209</td>\n      <td>3</td>\n      <td>11</td>\n      <td>0</td>\n      <td>0</td>\n      <td>-0.500000</td>\n      <td>0.866025</td>\n      <td>0.433884</td>\n      <td>...</td>\n      <td>17.822</td>\n      <td>13.128</td>\n      <td>10.751</td>\n      <td>15.610000</td>\n      <td>15.373357</td>\n      <td>3.861</td>\n      <td>0.276556</td>\n      <td>0.000000</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 45 columns</p>\n</div>"},"metadata":{}}],"execution_count":11},{"cell_type":"code","source":"# Ensure the data is sorted by ID and date\ndf_patchtst = df_patchtst.sort_values(['unique_id', 'ds'])\n\n# Define cutoffs\nmax_date = df_patchtst['ds'].max()\nval_days = 60\ntest_days = 60\n\ntest_start = max_date - pd.Timedelta(days=test_days)\nval_start = test_start - pd.Timedelta(days=val_days)\n\n# Split\ndf_train = df_patchtst[df_patchtst['ds'] < val_start]\ndf_val   = df_patchtst[(df_patchtst['ds'] >= val_start) & (df_patchtst['ds'] < test_start)]\ndf_test  = df_patchtst[df_patchtst['ds'] >= test_start]\n\n# Summary\nprint(f\"📅 Train: {df_train['ds'].min().date()} to {df_train['ds'].max().date()} — {len(df_train):,} rows\")\nprint(f\"📅 Val:   {df_val['ds'].min().date()} to {df_val['ds'].max().date()} — {len(df_val):,} rows\")\nprint(f\"📅 Test:  {df_test['ds'].min().date()} to {df_test['ds'].max().date()} — {len(df_test):,} rows\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:12:41.634736Z","iopub.execute_input":"2025-06-12T23:12:41.635274Z","iopub.status.idle":"2025-06-12T23:12:42.865744Z","shell.execute_reply.started":"2025-06-12T23:12:41.635251Z","shell.execute_reply":"2025-06-12T23:12:42.865081Z"},"jupyter":{"source_hidden":true}},"outputs":[{"name":"stdout","text":"📅 Train: 2011-12-08 to 2013-10-29 — 2,758,348 rows\n📅 Val:   2013-10-30 to 2013-12-28 — 304,831 rows\n📅 Test:  2013-12-29 to 2014-02-27 — 303,306 rows\n","output_type":"stream"}],"execution_count":15},{"cell_type":"code","source":"import torch","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:12:34.643884Z","iopub.execute_input":"2025-06-12T23:12:34.644430Z","iopub.status.idle":"2025-06-12T23:12:34.647677Z","shell.execute_reply.started":"2025-06-12T23:12:34.644406Z","shell.execute_reply":"2025-06-12T23:12:34.646815Z"},"jupyter":{"source_hidden":true}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"# Define trainer arguments\ntrainer_args = {\n    'accelerator': 'gpu' if torch.cuda.is_available() else 'cpu',\n    'devices': 1,\n    'strategy': 'auto'  # Safe for notebooks and multi-GPU\n}\n\n# Pass unpacked kwargs\nmodel = PatchTST(\n    h=1,\n    input_size=60,\n    max_steps=1000,\n    scaler_type='robust',\n    loss=MSE(),\n    **trainer_args  # <- ✅ correct way\n)\n\n# Initialize and fit\nnf = NeuralForecast(models=[model], freq='D')\nnf.fit(df=df_train)\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:17:15.656761Z","iopub.execute_input":"2025-06-12T23:17:15.657420Z","iopub.status.idle":"2025-06-12T23:17:57.592972Z","shell.execute_reply.started":"2025-06-12T23:17:15.657395Z","shell.execute_reply":"2025-06-12T23:17:57.592233Z"},"jupyter":{"source_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Sanity Checking: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Training: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"0f799acb1ba048a885ed86aa36b828a0"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Validation: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":""}},"metadata":{}}],"execution_count":19},{"cell_type":"code","source":"# Predict\nforecast_val = nf.predict()\nforecast_val = forecast_val.rename(columns={'PatchTST': 'y_pred'})\n\n# Merge with actuals\ndf_val_merged = forecast_val.merge(\n    df_val[['unique_id', 'ds', 'y']], on=['unique_id', 'ds']\n)\n\n# Metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nval_mae = mean_absolute_error(df_val_merged['y'], df_val_merged['y_pred'])\nval_rmse = mean_squared_error(df_val_merged['y'], df_val_merged['y_pred'], squared=False)\nval_r2 = r2_score(df_val_merged['y'], df_val_merged['y_pred'])\nmape = np.mean(\n    np.abs((df_val_merged['y'] - df_val_merged['y_pred']) / df_eval['y'].replace(0, np.nan))\n) * 100\nprint(f\"📊 Validation MAE: {val_mae:.2f}\")\nprint(f\"📊 Validation RMSE: {val_rmse:.2f}\")\nprint(f\"📈 Validation R²: {val_r2:.2f}\")\nprint(f\"🧪 Aligned Test MAPE: {mape:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:20:11.292099Z","iopub.execute_input":"2025-06-12T23:20:11.292700Z","iopub.status.idle":"2025-06-12T23:20:14.102800Z","shell.execute_reply.started":"2025-06-12T23:20:11.292673Z","shell.execute_reply":"2025-06-12T23:20:14.102140Z"},"jupyter":{"source_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ff79a016a73040ceb08cc7dd477c6ceb"}},"metadata":{}},{"name":"stdout","text":"📊 Validation MAE: 2.45\n📊 Validation RMSE: 4.04\n📈 Validation R²: 0.78\n🧪 Aligned Test MAPE: 45.39%\n","output_type":"stream"}],"execution_count":21},{"cell_type":"code","source":"# Get forecast\nforecast_test = nf.predict().rename(columns={'PatchTST': 'y_pred'})\n\n# Limit actuals to match forecast horizon\ndf_eval = df_patchtst.merge(forecast_test[['unique_id', 'ds']], on=['unique_id', 'ds'])\ndf_eval = df_eval.merge(forecast_test, on=['unique_id', 'ds'])\n\n# Compute metrics\nfrom sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score\n\nmae = mean_absolute_error(df_eval['y'], df_eval['y_pred'])\nrmse = mean_squared_error(df_eval['y'], df_eval['y_pred'], squared=False)\nr2 = r2_score(df_eval['y'], df_eval['y_pred'])\n\nmape = np.mean(\n    np.abs((df_eval['y'] - df_eval['y_pred']) / df_eval['y'].replace(0, np.nan))\n) * 100\n\nprint(f\"🧪 Aligned Test MAE: {mae:.2f}\")\nprint(f\"🧪 Aligned Test RMSE: {rmse:.2f}\")\nprint(f\"🧪 Aligned Test R² Score: {r2:.4f}\")\nprint(f\"🧪 Aligned Test MAPE: {mape:.2f}%\")\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-12T23:20:16.901728Z","iopub.execute_input":"2025-06-12T23:20:16.902431Z","iopub.status.idle":"2025-06-12T23:20:20.535187Z","shell.execute_reply.started":"2025-06-12T23:20:16.902408Z","shell.execute_reply":"2025-06-12T23:20:20.534434Z"},"jupyter":{"source_hidden":true}},"outputs":[{"output_type":"display_data","data":{"text/plain":"Predicting: |          | 0/? [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"82d98d43c69b443e8fc35d132cbae171"}},"metadata":{}},{"name":"stdout","text":"🧪 Aligned Test MAE: 2.45\n🧪 Aligned Test RMSE: 4.04\n🧪 Aligned Test R² Score: 0.7824\n🧪 Aligned Test MAPE: 56.94%\n","output_type":"stream"}],"execution_count":22},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"pip install pytorch_forecasting","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T05:59:37.460287Z","iopub.execute_input":"2025-06-13T05:59:37.460892Z","iopub.status.idle":"2025-06-13T05:59:42.701336Z","shell.execute_reply.started":"2025-06-13T05:59:37.460870Z","shell.execute_reply":"2025-06-13T05:59:42.700537Z"},"collapsed":true,"jupyter":{"outputs_hidden":true}},"outputs":[{"name":"stdout","text":"Collecting pytorch_forecasting\n  Downloading pytorch_forecasting-1.3.0-py3-none-any.whl.metadata (13 kB)\nRequirement already satisfied: numpy<=3.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.26.4)\nRequirement already satisfied: torch!=2.0.1,<3.0.0,>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (2.6.0+cu124)\nCollecting lightning<3.0.0,>=2.0.0 (from pytorch_forecasting)\n  Downloading lightning-2.5.1.post0-py3-none-any.whl.metadata (39 kB)\nRequirement already satisfied: scipy<2.0,>=1.8 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.15.2)\nRequirement already satisfied: pandas<3.0.0,>=1.3.0 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (2.2.3)\nRequirement already satisfied: scikit-learn<2.0,>=1.2 in /usr/local/lib/python3.11/dist-packages (from pytorch_forecasting) (1.2.2)\nRequirement already satisfied: PyYAML<8.0,>=5.4 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (6.0.2)\nRequirement already satisfied: fsspec<2026.0,>=2022.5.0 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2025.3.2)\nRequirement already satisfied: lightning-utilities<2.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.14.3)\nCollecting packaging<25.0,>=20.0 (from lightning<3.0.0,>=2.0.0->pytorch_forecasting)\n  Downloading packaging-24.2-py3-none-any.whl.metadata (3.2 kB)\nRequirement already satisfied: torchmetrics<3.0,>=0.7.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.7.1)\nRequirement already satisfied: tqdm<6.0,>=4.57.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.67.1)\nRequirement already satisfied: typing-extensions<6.0,>=4.4.0 in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (4.13.2)\nRequirement already satisfied: pytorch-lightning in /usr/local/lib/python3.11/dist-packages (from lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.5.1.post0)\nRequirement already satisfied: mkl_fft in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (1.3.8)\nRequirement already satisfied: mkl_random in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (1.2.4)\nRequirement already satisfied: mkl_umath in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (0.1.1)\nRequirement already satisfied: mkl in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (2025.1.0)\nRequirement already satisfied: tbb4py in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (2022.1.0)\nRequirement already satisfied: mkl-service in /usr/local/lib/python3.11/dist-packages (from numpy<=3.0.0->pytorch_forecasting) (2.4.1)\nRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2.9.0.post0)\nRequirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2025.2)\nRequirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas<3.0.0,>=1.3.0->pytorch_forecasting) (2025.2)\nRequirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (1.5.0)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from scikit-learn<2.0,>=1.2->pytorch_forecasting) (3.6.0)\nRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.18.0)\nRequirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.4.2)\nRequirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.1.6)\nRequirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\nRequirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\nRequirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\nRequirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (9.1.0.70)\nRequirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.5.8)\nRequirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (11.2.1.3)\nRequirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (10.3.5.147)\nRequirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (11.6.1.9)\nRequirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.3.1.170)\nRequirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (0.6.2)\nRequirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (2.21.5)\nRequirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\nRequirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (12.4.127)\nRequirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.2.0)\nRequirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.13.1)\nRequirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.0)\nRequirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /usr/local/lib/python3.11/dist-packages (from fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.11.18)\nRequirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities<2.0,>=0.10.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (75.2.0)\nRequirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=1.3.0->pytorch_forecasting) (1.17.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch!=2.0.1,<3.0.0,>=2.0.0->pytorch_forecasting) (3.0.2)\nRequirement already satisfied: intel-openmp<2026,>=2024 in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=3.0.0->pytorch_forecasting) (2024.2.0)\nRequirement already satisfied: tbb==2022.* in /usr/local/lib/python3.11/dist-packages (from mkl->numpy<=3.0.0->pytorch_forecasting) (2022.1.0)\nRequirement already satisfied: tcmlib==1.* in /usr/local/lib/python3.11/dist-packages (from tbb==2022.*->mkl->numpy<=3.0.0->pytorch_forecasting) (1.3.0)\nRequirement already satisfied: intel-cmplr-lib-rt in /usr/local/lib/python3.11/dist-packages (from mkl_umath->numpy<=3.0.0->pytorch_forecasting) (2024.2.0)\nRequirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (2.6.1)\nRequirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.3.2)\nRequirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (25.3.0)\nRequirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.6.0)\nRequirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (6.4.3)\nRequirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (0.3.1)\nRequirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (1.20.0)\nRequirement already satisfied: intel-cmplr-lib-ur==2024.2.0 in /usr/local/lib/python3.11/dist-packages (from intel-openmp<2026,>=2024->mkl->numpy<=3.0.0->pytorch_forecasting) (2024.2.0)\nRequirement already satisfied: idna>=2.0 in /usr/local/lib/python3.11/dist-packages (from yarl<2.0,>=1.17.0->aiohttp!=4.0.0a0,!=4.0.0a1->fsspec[http]<2026.0,>=2022.5.0->lightning<3.0.0,>=2.0.0->pytorch_forecasting) (3.10)\nDownloading pytorch_forecasting-1.3.0-py3-none-any.whl (197 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m197.7/197.7 kB\u001b[0m \u001b[31m6.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading lightning-2.5.1.post0-py3-none-any.whl (819 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m819.0/819.0 kB\u001b[0m \u001b[31m25.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hDownloading packaging-24.2-py3-none-any.whl (65 kB)\n\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m65.5/65.5 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n\u001b[?25hInstalling collected packages: packaging, lightning, pytorch_forecasting\n  Attempting uninstall: packaging\n    Found existing installation: packaging 25.0\n    Uninstalling packaging-25.0:\n      Successfully uninstalled packaging-25.0\n\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\ndatasets 3.6.0 requires fsspec[http]<=2025.3.0,>=2023.1.0, but you have fsspec 2025.3.2 which is incompatible.\ncesium 0.12.4 requires numpy<3.0,>=2.0, but you have numpy 1.26.4 which is incompatible.\nbigframes 1.42.0 requires rich<14,>=12.4.4, but you have rich 14.0.0 which is incompatible.\nplotnine 0.14.5 requires matplotlib>=3.8.0, but you have matplotlib 3.7.2 which is incompatible.\npandas-gbq 0.28.0 requires google-api-core<3.0.0dev,>=2.10.2, but you have google-api-core 1.34.1 which is incompatible.\nmlxtend 0.23.4 requires scikit-learn>=1.3.1, but you have scikit-learn 1.2.2 which is incompatible.\u001b[0m\u001b[31m\n\u001b[0mSuccessfully installed lightning-2.5.1.post0 packaging-24.2 pytorch_forecasting-1.3.0\nNote: you may need to restart the kernel to use updated packages.\n","output_type":"stream"}],"execution_count":40},{"cell_type":"code","source":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom neuralforecast import NeuralForecast\nfrom neuralforecast.models import NBEATSx\nfrom neuralforecast.losses.pytorch import MAE\nimport pytorch_lightning as pl\n\n# Set random seed for reproducibility\npl.seed_everything(42)\n\n# Set sequence length parameters\nWINDOW = 14  # Input sequence length (lookback)\nH = 1        # Forecast horizon\n\n# Assuming df_features is your processed dataframe and is already loaded\n# We need to prepare it for NeuralForecast format which expects a specific structure\n\ndef prepare_data_for_neuralforecast(df, target_col='total_kwh', id_col='LCLid', time_col='day'):\n    \"\"\"\n    Prepare smart meter data for NeuralForecast library\n    \n    Parameters:\n    -----------\n    df : pandas DataFrame\n        The processed smart meter data\n    target_col : str\n        The target column to forecast\n    id_col : str\n        The household identifier column\n    time_col : str\n        The date column\n    \n    Returns:\n    --------\n    train_df, val_df, test_df and feature column names\n    \"\"\"\n    # Ensure time column is datetime\n    df[time_col] = pd.to_datetime(df[time_col])\n    \n    # Sort data\n    df = df.sort_values([id_col, time_col])\n    \n    # Get all feature columns (excluding id, date, and target)\n    exclude_cols = [id_col, time_col, target_col]\n    feat_cols = [col for col in df.columns if col not in exclude_cols]\n    \n    # Split into train, validation, and test\n    households = df[id_col].unique()\n    \n    # Create train/val/test splits (using the same method as in your original code)\n    cutoff_dates = {}\n    for hh in households:\n        hh_data = df[df[id_col] == hh]\n        dates = hh_data[time_col].sort_values().unique()\n        \n        if len(dates) < WINDOW + 60:  # Skip households with too little data\n            continue\n            \n        val_cutoff = dates[-90-60]  # 90 test days, 60 val days\n        test_cutoff = dates[-90]    # 90 test days\n        \n        cutoff_dates[hh] = {\"val\": val_cutoff, \"test\": test_cutoff}\n    \n    # Create dataframes\n    train_dfs = []\n    val_dfs = []\n    test_dfs = []\n    \n    for hh in cutoff_dates:\n        hh_data = df[df[id_col] == hh].copy()\n        \n        train_df_hh = hh_data[hh_data[time_col] <= cutoff_dates[hh][\"val\"]]\n        val_df_hh = hh_data[(hh_data[time_col] > cutoff_dates[hh][\"val\"]) & \n                           (hh_data[time_col] <= cutoff_dates[hh][\"test\"])]\n        test_df_hh = hh_data[hh_data[time_col] > cutoff_dates[hh][\"test\"]]\n        \n        train_dfs.append(train_df_hh)\n        val_dfs.append(val_df_hh)\n        test_dfs.append(test_df_hh)\n    \n    train_df = pd.concat(train_dfs)\n    val_df = pd.concat(val_dfs)\n    test_df = pd.concat(test_dfs)\n    \n    # Format specifically for NeuralForecast\n    # The dataframe needs: unique_id, ds, y, and exogenous features\n    train_df = train_df.rename(columns={id_col: 'unique_id', \n                                      time_col: 'ds', \n                                      target_col: 'y'})\n    val_df = val_df.rename(columns={id_col: 'unique_id', \n                                   time_col: 'ds', \n                                   target_col: 'y'})\n    test_df = test_df.rename(columns={id_col: 'unique_id', \n                                    time_col: 'ds', \n                                    target_col: 'y'})\n    \n    return train_df, val_df, test_df, feat_cols\n\n# Example usage of the prepare function (uncomment when ready to use)\n# train_df, val_df, test_df, feat_cols = prepare_data_for_neuralforecast(df_features)\n\n# Create and train the N-BEATS model using NeuralForecast\ndef train_nbeats_model(train_df, val_df, feat_cols, window=14, horizon=1, max_steps=1000):\n    \"\"\"\n    Train an N-BEATS model on smart meter data using NeuralForecast\n    \n    Parameters:\n    -----------\n    train_df : pandas DataFrame\n        Training data in NeuralForecast format (unique_id, ds, y, features)\n    val_df : pandas DataFrame\n        Validation data in same format\n    feat_cols : list\n        List of feature column names\n    window : int\n        Input sequence length (lookback window)\n    horizon : int\n        Forecast horizon\n    max_steps : int\n        Maximum training steps\n    \n    Returns:\n    --------\n    Trained NeuralForecast model\n    \"\"\"\n    # Configure NBEATSx model\n    nbeatsx = NBEATSx(\n        h=horizon,                   # Forecast horizon\n        input_size=window,           # Lookback window\n        futr_exog_list=feat_cols,    # Future features (known in advance)\n        hist_exog_list=feat_cols,    # Historical features\n        stack_types=[\"trend\", \"seasonality\"],  # Use trend and seasonality stacks\n        n_blocks=[3, 3],            # Number of blocks in each stack\n        mlp_units=[[512, 512], [512, 512]],  # Hidden units in each block\n        dropout=0.1,                 # Dropout rate\n        loss=MAE(),                  # Training loss\n        valid_loss=MAE(),            # Validation loss\n        learning_rate=3e-4,          # Learning rate\n        max_steps=max_steps,         # Maximum training steps\n        \n        # Trainer arguments\n        accelerator=\"auto\",          # Use GPU if available\n        devices=1,                   # Number of devices\n        enable_progress_bar=True,    # Show progress bar\n        enable_model_summary=True,   # Show model summary\n        callbacks=[pl.callbacks.early_stopping.EarlyStopping(\n            monitor=\"val_loss\",\n            patience=10,\n            mode=\"min\"\n        )]\n    )\n    \n    # Create NeuralForecast object with our model\n    nf = NeuralForecast(models=[nbeatsx], freq=\"1D\")\n    \n    # Calculate validation size\n    val_size = len(val_df)\n    \n    # Train the model\n    nf.fit(df=train_df, val_size=val_size)\n    \n    return nf\n\n# Evaluate the model\ndef evaluate_nbeats_model(nf, test_df, plot_n=3):\n    \"\"\"\n    Evaluate N-BEATS model on test data and plot results\n    \n    Parameters:\n    -----------\n    nf : NeuralForecast\n        Trained NeuralForecast model\n    test_df : pandas DataFrame\n        Test data in NeuralForecast format\n    plot_n : int\n        Number of households to plot\n    \n    Returns:\n    --------\n    Evaluation metrics\n    \"\"\"\n    # Make predictions\n    forecast = nf.predict(df=test_df)\n    \n    # Calculate metrics\n    test_df_with_preds = test_df.merge(forecast, on=['unique_id', 'ds'], how='left')\n    test_df_with_preds['error'] = test_df_with_preds['y'] - test_df_with_preds['NBEATSx']\n    \n    # Overall metrics\n    mae = test_df_with_preds['error'].abs().mean()\n    mse = (test_df_with_preds['error'] ** 2).mean()\n    rmse = np.sqrt(mse)\n    mape = (test_df_with_preds['error'].abs() / test_df_with_preds['y'].abs()).mean() * 100\n    \n    print(f\"Test MAE: {mae:.4f}\")\n    print(f\"Test MSE: {mse:.4f}\")\n    print(f\"Test RMSE: {rmse:.4f}\")\n    print(f\"Test MAPE: {mape:.4f}%\")\n    \n    # Plot predictions for a few households\n    if plot_n > 0:\n        unique_households = test_df_with_preds['unique_id'].unique()\n        households_to_plot = np.random.choice(unique_households, min(plot_n, len(unique_households)), replace=False)\n        \n        for hh in households_to_plot:\n            hh_data = test_df_with_preds[test_df_with_preds['unique_id'] == hh].sort_values('ds')\n            \n            plt.figure(figsize=(12, 4))\n            plt.plot(hh_data['ds'], hh_data['y'], 'b-', label='Actual', marker='o')\n            plt.plot(hh_data['ds'], hh_data['NBEATSx'], 'r--', label='N-BEATS Forecast', marker='x')\n            plt.title(f'Household {hh}: Actual vs. Predicted Energy Consumption')\n            plt.xlabel('Date')\n            plt.ylabel('Energy Consumption (kWh)')\n            plt.legend()\n            plt.grid(True, alpha=0.3)\n            plt.tight_layout()\n            plt.show()\n    \n    return {'mae': mae, 'mse': mse, 'rmse': rmse, 'mape': mape}\n\n# COMPLETE EXAMPLE WORKFLOW\n# Uncomment and customize when ready to run\n\"\"\"\n# 1. Load and prepare your data\n# Assuming df_features is your processed dataframe with all features\ntrain_df, val_df, test_df, feat_cols = prepare_data_for_neuralforecast(df_features)\n\nprint(f\"Training data: {train_df.shape}\")\nprint(f\"Validation data: {val_df.shape}\")\nprint(f\"Test data: {test_df.shape}\")\nprint(f\"Features: {len(feat_cols)}\")\n\n# 2. Train the N-BEATS model\nnf = train_nbeats_model(\n    train_df=train_df,\n    val_df=val_df,\n    feat_cols=feat_cols,\n    window=14,\n    horizon=1,\n    max_steps=1000\n)\n\n# 3. Evaluate the model\nmetrics = evaluate_nbeats_model(nf, test_df, plot_n=3)\n\n# 4. Save the model (optional)\nimport pickle\nwith open('nbeats_smart_meter_model.pkl', 'wb') as f:\n    pickle.dump(nf, f)\n\"\"\"","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T06:01:24.962069Z","iopub.execute_input":"2025-06-13T06:01:24.962863Z","iopub.status.idle":"2025-06-13T06:01:24.985453Z","shell.execute_reply.started":"2025-06-13T06:01:24.962835Z","shell.execute_reply":"2025-06-13T06:01:24.984709Z"}},"outputs":[{"execution_count":46,"output_type":"execute_result","data":{"text/plain":"'\\n# 1. Load and prepare your data\\n# Assuming df_features is your processed dataframe with all features\\ntrain_df, val_df, test_df, feat_cols = prepare_data_for_neuralforecast(df_features)\\n\\nprint(f\"Training data: {train_df.shape}\")\\nprint(f\"Validation data: {val_df.shape}\")\\nprint(f\"Test data: {test_df.shape}\")\\nprint(f\"Features: {len(feat_cols)}\")\\n\\n# 2. Train the N-BEATS model\\nnf = train_nbeats_model(\\n    train_df=train_df,\\n    val_df=val_df,\\n    feat_cols=feat_cols,\\n    window=14,\\n    horizon=1,\\n    max_steps=1000\\n)\\n\\n# 3. Evaluate the model\\nmetrics = evaluate_nbeats_model(nf, test_df, plot_n=3)\\n\\n# 4. Save the model (optional)\\nimport pickle\\nwith open(\\'nbeats_smart_meter_model.pkl\\', \\'wb\\') as f:\\n    pickle.dump(nf, f)\\n'"},"metadata":{}}],"execution_count":46},{"cell_type":"code","source":"train_df, val_df, test_df, feat_cols = prepare_data_for_neuralforecast(df_features)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-13T06:01:30.934915Z","iopub.execute_input":"2025-06-13T06:01:30.935569Z","execution_failed":"2025-06-13T06:01:39.946Z"}},"outputs":[],"execution_count":null},{"cell_type":"code","source":"","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}