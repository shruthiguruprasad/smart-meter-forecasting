{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2025-06-07T06:58:38.071714Z",
     "iopub.status.busy": "2025-06-07T06:58:38.071456Z",
     "iopub.status.idle": "2025-06-07T06:58:38.075668Z",
     "shell.execute_reply": "2025-06-07T06:58:38.074859Z",
     "shell.execute_reply.started": "2025-06-07T06:58:38.071690Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "# import os\n",
    "# for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "#     for filename in filenames:\n",
    "#         print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T06:58:38.076917Z",
     "iopub.status.busy": "2025-06-07T06:58:38.076632Z",
     "iopub.status.idle": "2025-06-07T06:58:38.117228Z",
     "shell.execute_reply": "2025-06-07T06:58:38.116522Z",
     "shell.execute_reply.started": "2025-06-07T06:58:38.076890Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append(\"/kaggle/input/utility-smart-meter/src\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T06:58:38.118370Z",
     "iopub.status.busy": "2025-06-07T06:58:38.118082Z",
     "iopub.status.idle": "2025-06-07T06:58:38.134007Z",
     "shell.execute_reply": "2025-06-07T06:58:38.133374Z",
     "shell.execute_reply.started": "2025-06-07T06:58:38.118344Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress excessive TensorFlow logging\n",
    "import os\n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '2'\n",
    "\n",
    "#%% ------------------------------------------------\n",
    "# 1) IMPORT NECESSARY MODULES\n",
    "#%% ------------------------------------------------\n",
    "from data.data_loader import load_all_raw_data\n",
    "from data.data_cleaner import clean_and_merge_all_data\n",
    "from features.feature_pipeline import create_comprehensive_features\n",
    "from features.splitters import prepare_forecasting_data, prepare_weekahead_data\n",
    "from utils.helpers import reduce_memory_footprint\n",
    "\n",
    "from features.splitters import prepare_forecasting_data\n",
    "from utils.sequence_builder import build_global_sequences\n",
    "from models.lstm_model import LSTMForecaster\n",
    "from evaluation.forecast_evaluation import (\n",
    "    compute_forecast_metrics,\n",
    "    print_split_summary,\n",
    "    evaluate_model,\n",
    "    evaluate_peak_performance,\n",
    "    evaluate_forecast_residuals\n",
    ")\n",
    "from visualization.forecast_plots import (\n",
    "    plot_feature_importance,\n",
    "    plot_actual_vs_predicted,\n",
    "    plot_peak_actual_vs_predicted\n",
    ")\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T06:58:38.135134Z",
     "iopub.status.busy": "2025-06-07T06:58:38.134859Z",
     "iopub.status.idle": "2025-06-07T06:59:24.945087Z",
     "shell.execute_reply": "2025-06-07T06:59:24.944461Z",
     "shell.execute_reply.started": "2025-06-07T06:58:38.135109Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Set the base path where all your data files and folders are located\n",
    "data_path = \"/kaggle/input/smart-meters-in-london\"\n",
    "\n",
    "# Call the function to load all raw datasets: consumption, household, weather, and holiday data\n",
    "raw_data = load_all_raw_data(data_path)\n",
    "\n",
    "# Extract each dataset from the returned dictionary for easier access\n",
    "df_consumption = raw_data[\"consumption\"]  # Half-hourly electricity consumption records\n",
    "df_household = raw_data[\"household\"]      # Household metadata (e.g., tariff, ACORN group)\n",
    "df_weather = raw_data[\"weather\"]          # Daily weather data\n",
    "df_holiday = raw_data[\"holiday\"]          # UK bank holiday dates\n",
    "\n",
    "# Display the first few rows of the consumption data to confirm successful loading\n",
    "df_consumption.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T06:59:24.948262Z",
     "iopub.status.busy": "2025-06-07T06:59:24.947806Z",
     "iopub.status.idle": "2025-06-07T06:59:47.563940Z",
     "shell.execute_reply": "2025-06-07T06:59:47.563255Z",
     "shell.execute_reply.started": "2025-06-07T06:59:24.948239Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Clean and merge all raw data\n",
    "df_final = clean_and_merge_all_data(raw_data)\n",
    "\n",
    "# View the final cleaned and enriched dataset\n",
    "df_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T06:59:47.565030Z",
     "iopub.status.busy": "2025-06-07T06:59:47.564795Z",
     "iopub.status.idle": "2025-06-07T07:00:12.818668Z",
     "shell.execute_reply": "2025-06-07T07:00:12.817786Z",
     "shell.execute_reply.started": "2025-06-07T06:59:47.565013Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Run the full feature pipeline\n",
    "df_features = create_comprehensive_features(df_final)\n",
    "df_features['household_code'] = LabelEncoder().fit_transform(df_features['LCLid'])\n",
    "\n",
    "# Check the final DataFrame\n",
    "df_features.head()\n",
    "\n",
    "print(f\"‚úÖ Feature engineering completed:\")\n",
    "print(f\"   üìä Total samples: {len(df_features):,}\")\n",
    "print(f\"   üìÖ Date range: {df_features['day'].min()} to {df_features['day'].max()}\")\n",
    "print(f\"   üè† Households: {df_features['LCLid'].nunique()}\")\n",
    "print(f\"   üîß Features created: {len(df_features.columns)} total columns\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:12.822156Z",
     "iopub.status.busy": "2025-06-07T07:00:12.821813Z",
     "iopub.status.idle": "2025-06-07T07:00:21.322667Z",
     "shell.execute_reply": "2025-06-07T07:00:21.321556Z",
     "shell.execute_reply.started": "2025-06-07T07:00:12.822138Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "df_features = reduce_memory_footprint(df_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:21.324218Z",
     "iopub.status.busy": "2025-06-07T07:00:21.323696Z",
     "iopub.status.idle": "2025-06-07T07:00:21.337827Z",
     "shell.execute_reply": "2025-06-07T07:00:21.337026Z",
     "shell.execute_reply.started": "2025-06-07T07:00:21.324188Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "cat_cols = [\n",
    "    \"Acorn\", \"Acorn_grouped\", \"stdorToU\", \"season\",\n",
    "    \"holiday_category\",  # add any other categorical features here\n",
    "]\n",
    "for col in cat_cols:\n",
    "    if col in df_features.columns and df_features[col].dtype.name in (\"category\", \"object\"):\n",
    "        df_features[col] = df_features[col].astype(\"category\").cat.codes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:21.339620Z",
     "iopub.status.busy": "2025-06-07T07:00:21.339369Z",
     "iopub.status.idle": "2025-06-07T07:00:21.346447Z",
     "shell.execute_reply": "2025-06-07T07:00:21.345606Z",
     "shell.execute_reply.started": "2025-06-07T07:00:21.339601Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# LSTM FORECASTING CONFIGURATION\n",
    "\n",
    "CONFIG = {\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Data Scope & Splitting\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    'forecast_scope': 'subset',       # 'single', 'subset', or 'all'\n",
    "    'sample_household': 'MAC000001',  # used if forecast_scope='single'\n",
    "    'subset_households': 100,         # int (number of random households) or list of LCLid\n",
    "    'seed': 42,                       # random seed for reproducibility\n",
    "\n",
    "    'test_days': 90,                  # number of days for test split\n",
    "    'val_days': 60,                   # number of days for validation split\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Sequence & Model Hyperparameters\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    'seq_length': 14,                 # number of time steps per LSTM input window\n",
    "    'hidden_units': [128, 64],        # LSTM layer sizes (list of integers)\n",
    "    'dropout': 0.2,                   # dropout rate for regularization\n",
    "    'learning_rate': 0.001,           # Adam optimizer learning rate\n",
    "\n",
    "    'use_embedding': True,            # whether to include household embedding\n",
    "    'embedding_dim': 8,               # dimension of embedding for household_code\n",
    "\n",
    "    'scale_features': True,           # standard‚Äêscale input features\n",
    "    'scale_target': True,             # standard‚Äêscale target variable\n",
    "\n",
    "    'batch_size': 64,                 # batch size for training\n",
    "    'epochs': 50,                     # maximum number of training epochs\n",
    "    'early_stopping_patience': 7,     # patience for early stopping (in epochs)\n",
    "\n",
    "    'forecast_horizon': 'day',        # 'day', 'week', or 'both'\n",
    "\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    # Column Names & Grouping\n",
    "    # ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ\n",
    "    'group_col': 'LCLid',             # household identifier column\n",
    "    'household_col': 'household_code', # integer‚Äêcoded household ID column\n",
    "    'date_col': 'day'\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:26.151298Z",
     "iopub.status.busy": "2025-06-07T07:00:26.151001Z",
     "iopub.status.idle": "2025-06-07T07:00:26.299549Z",
     "shell.execute_reply": "2025-06-07T07:00:26.298691Z",
     "shell.execute_reply.started": "2025-06-07T07:00:26.151278Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# Determine which households to include\n",
    "all_households = df_features['LCLid'].unique()\n",
    "\n",
    "if CONFIG['forecast_scope'] == 'single':\n",
    "    hh_filter = [CONFIG['sample_household']]\n",
    "elif CONFIG['forecast_scope'] == 'subset':\n",
    "    sh = CONFIG['subset_households']\n",
    "    if isinstance(sh, int):\n",
    "        np.random.seed(CONFIG['seed'])\n",
    "        hh_filter = np.random.choice(all_households, size=sh, replace=False).tolist()\n",
    "    elif isinstance(sh, list):\n",
    "        hh_filter = sh\n",
    "    else:\n",
    "        raise ValueError(\"subset_households must be an int or a list of LCLid\")\n",
    "else:\n",
    "    hh_filter = all_households.tolist()\n",
    "\n",
    "print(f\"üè† Forecasting only these households ({len(hh_filter)}): {hh_filter[:5]}{'...' if len(hh_filter)>5 else ''}\")\n",
    "\n",
    "# Filter df_features to include only selected households\n",
    "df_sel = df_features[df_features['LCLid'].isin(hh_filter)].copy()\n",
    "\n",
    "#%% ------------------------------------------------\n",
    "# 2) SPLIT DATA FOR DAY‚ÄêAHEAD FORECASTING (ON FILTERED DATA)\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "print(\"\\nüìä Preparing day‚Äêahead data split (filtered households)‚Ä¶\")\n",
    "train_df, val_df, test_df, feature_cols, target_col, _ = prepare_forecasting_data(\n",
    "    df_sel,\n",
    "    target_col=\"total_kwh\",\n",
    "    test_days=90,\n",
    "    val_days=60\n",
    ")\n",
    "print(f\"   ‚ñ∂ Training samples:   {len(train_df):,}\")\n",
    "print(f\"   ‚ñ∂ Validation samples: {len(val_df):,}\")\n",
    "print(f\"   ‚ñ∂ Test samples:       {len(test_df):,}\")\n",
    "print(f\"   ‚ñ∂ Features:           {len(feature_cols)}\")\n",
    "print(f\"   ‚ñ∂ Target:             {target_col}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:41.780687Z",
     "iopub.status.busy": "2025-06-07T07:00:41.779753Z",
     "iopub.status.idle": "2025-06-07T07:00:57.468187Z",
     "shell.execute_reply": "2025-06-07T07:00:57.467198Z",
     "shell.execute_reply.started": "2025-06-07T07:00:41.780652Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% ------------------------------------------------\n",
    "# BUILD SEQUENCES FOR GLOBAL LSTM\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "seq_len = 14\n",
    "print(f\"üîÑ Building sequences with seq_len = {seq_len}‚Ä¶\")\n",
    "\n",
    "(\n",
    " X_train, y_train, hh_train, date_train,\n",
    " X_val,   y_val,   hh_val,   date_val,\n",
    " X_test,  y_test,  hh_test,  date_test\n",
    ") = build_global_sequences_with_dates(\n",
    "    train_df, val_df, test_df,\n",
    "    feature_cols=feature_cols,\n",
    "    target_col=\"label_1\",   # day‚Äêahead\n",
    "    seq_len=seq_len,\n",
    "    group_col=\"LCLid\",\n",
    "    household_col=\"household_code\",\n",
    "    date_col=\"day\"\n",
    ")\n",
    "\n",
    "\n",
    "print(f\"   ‚ñ∂ X_train shape: {X_train.shape}\")\n",
    "print(f\"   ‚ñ∂ y_train shape: {y_train.shape}\")\n",
    "print(f\"   ‚ñ∂ X_val   shape: {X_val.shape}\")\n",
    "print(f\"   ‚ñ∂ y_val   shape: {y_val.shape}\")\n",
    "print(f\"   ‚ñ∂ X_test  shape: {X_test.shape}\")\n",
    "print(f\"   ‚ñ∂ y_test  shape: {y_test.shape}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:57.469934Z",
     "iopub.status.busy": "2025-06-07T07:00:57.469654Z",
     "iopub.status.idle": "2025-06-07T07:02:34.292972Z",
     "shell.execute_reply": "2025-06-07T07:02:34.292317Z",
     "shell.execute_reply.started": "2025-06-07T07:00:57.469911Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% ------------------------------------------------\n",
    "# INSTANTIATE & BUILD LSTM MODEL\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "lstm_config = {\n",
    "    \"seq_length\": seq_len,\n",
    "    \"n_features\": len(feature_cols),\n",
    "    \"hidden_units\": CONFIG['hidden_units'],\n",
    "    \"dropout\": CONFIG['dropout'],\n",
    "    \"learning_rate\": CONFIG['learning_rate'],\n",
    "    \"use_embedding\": CONFIG['use_embedding'],\n",
    "    \"embedding_dim\": CONFIG['embedding_dim'],\n",
    "    \"scale_features\": CONFIG['scale_features'],\n",
    "    \"scale_target\": CONFIG['scale_target'],\n",
    "    \"random_state\": CONFIG['seed']\n",
    "}\n",
    "\n",
    "print(\"üöÄ Building LSTMForecaster‚Ä¶\")\n",
    "model = LSTMForecaster(**lstm_config)\n",
    "\n",
    "# If you want to see the summary now:\n",
    "model.build_model(n_features=len(feature_cols),\n",
    "                  n_households=df_features['household_code'].nunique())\n",
    "model.get_model_summary()\n",
    "\n",
    "#%% ------------------------------------------------\n",
    "# TRAIN LSTM MODEL\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "print(\"\\nüèãÔ∏è Training LSTM model‚Ä¶\")\n",
    "history = model.fit(\n",
    "    X_train, y_train,\n",
    "    X_val=X_val, y_val=y_val,\n",
    "    household_train=hh_train, household_val=hh_val,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    early_stopping=True,\n",
    "    patience=CONFIG['early_stopping_patience'],\n",
    "    verbose=2\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:02:34.294380Z",
     "iopub.status.busy": "2025-06-07T07:02:34.294084Z",
     "iopub.status.idle": "2025-06-07T07:02:46.445732Z",
     "shell.execute_reply": "2025-06-07T07:02:46.444934Z",
     "shell.execute_reply.started": "2025-06-07T07:02:34.294353Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "y_train_pred = model.predict(X_train, hh_train)\n",
    "y_val_pred   = model.predict(X_val,   hh_val)\n",
    "y_test_pred  = model.predict(X_test,  hh_test)\n",
    "\n",
    "train_metrics = model.evaluate(X_train, y_train, hh_train)\n",
    "val_metrics   = model.evaluate(X_val,   y_val,   hh_val)\n",
    "test_metrics  = model.evaluate(X_test,  y_test,  hh_test)\n",
    "\n",
    "print(\"\\nüìä OVERALL LSTM FORECAST EVALUATION\")\n",
    "print(\"----------------------------------------\")\n",
    "print_split_summary(\"Train\", y_train, y_train_pred)\n",
    "print_split_summary(\"Val\",   y_val,   y_val_pred)\n",
    "print_split_summary(\"Test\",  y_test,  y_test_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:02:46.448163Z",
     "iopub.status.busy": "2025-06-07T07:02:46.447769Z",
     "iopub.status.idle": "2025-06-07T07:02:47.592969Z",
     "shell.execute_reply": "2025-06-07T07:02:47.592148Z",
     "shell.execute_reply.started": "2025-06-07T07:02:46.448145Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "#%% ------------------------------------------------\n",
    "# PLOT ACTUAL vs PREDICTED ‚Äì SAMPLE HOUSEHOLDS\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "# Pick three random households from the test set\n",
    "unique_hh = np.unique(hh_test)\n",
    "sample_hhs = np.random.choice(unique_hh, size=3, replace=False)\n",
    "\n",
    "for hh in sample_hhs:\n",
    "    # Mask on hh_test, not on test_df\n",
    "    hh_mask = (hh_test == hh)\n",
    "\n",
    "    dates = date_test[hh_mask]\n",
    "    y_true_hh = y_test[hh_mask]\n",
    "    y_pred_hh = y_test_pred[hh_mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(dates, y_true_hh, label=\"Actual\", marker='o', linestyle='-')\n",
    "    plt.plot(dates, y_pred_hh, label=\"Predicted\", marker='x', linestyle='--')\n",
    "    plt.title(f\"Household {hh}: Actual vs Predicted (Day‚ÄêAhead)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"kWh\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "#%% ------------------------------------------------\n",
    "# PLOT RESIDUALS ‚Äì TEST SPLIT\n",
    "#%% ------------------------------------------------\n",
    "\n",
    "# Residuals vs. time\n",
    "residuals = y_test - y_test_pred\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.scatter(date_test, residuals, alpha=0.3)\n",
    "plt.hlines(0, xmin=date_test.min(), xmax=date_test.max(), colors=\"red\")\n",
    "plt.title(\"Residuals vs. Time (Test Split)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual (Actual ‚àí Predicted)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:02:47.594040Z",
     "iopub.status.busy": "2025-06-07T07:02:47.593836Z",
     "iopub.status.idle": "2025-06-07T07:02:47.691133Z",
     "shell.execute_reply": "2025-06-07T07:02:47.690531Z",
     "shell.execute_reply.started": "2025-06-07T07:02:47.594024Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "print(\"\\nüìä Preparing week‚Äêahead data split‚Ä¶\")\n",
    "train_df7, val_df7, test_df7, feature_cols7, target_col7, _ = prepare_weekahead_data(\n",
    "    df_sel,        # unfiltered df_final if needed, but df_sel already contains desired households\n",
    "    df_sel,        # we can pass df_sel for features too\n",
    "    test_days=CONFIG['test_days'],\n",
    "    val_days=CONFIG['val_days']\n",
    ")\n",
    "print(f\"   ‚ñ∂ Training samples (week‚Äêahead):   {len(train_df7):,}\")\n",
    "print(f\"   ‚ñ∂ Validation samples (week‚Äêahead): {len(val_df7):,}\")\n",
    "print(f\"   ‚ñ∂ Test samples (week‚Äêahead):       {len(test_df7):,}\")\n",
    "print(f\"   ‚ñ∂ Features:                        {len(feature_cols7)}\")\n",
    "print(f\"   ‚ñ∂ Target:                          {target_col7}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:02:47.692132Z",
     "iopub.status.busy": "2025-06-07T07:02:47.691911Z",
     "iopub.status.idle": "2025-06-07T07:03:03.034856Z",
     "shell.execute_reply": "2025-06-07T07:03:03.034102Z",
     "shell.execute_reply.started": "2025-06-07T07:02:47.692116Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ### 5.2 Build Sequences (Week‚ÄêAhead) with Dates\n",
    "\n",
    "\n",
    "print(f\"üîÑ Building week‚Äêahead sequences with seq_len = {seq_len}‚Ä¶\")\n",
    "\n",
    "(\n",
    "    X_train7, y_train7, hh_train7, date_train7,\n",
    "    X_val7,   y_val7,   hh_val7,   date_val7,\n",
    "    X_test7,  y_test7,  hh_test7,  date_test7\n",
    ") = build_global_sequences_with_dates(\n",
    "    train_df7, val_df7, test_df7,\n",
    "    feature_cols=feature_cols7,\n",
    "    target_col=\"label_7\",             # week‚Äêahead label\n",
    "    seq_len=seq_len,\n",
    "    group_col=CONFIG['group_col'],\n",
    "    household_col=CONFIG['household_col'],\n",
    "    date_col=CONFIG['date_col']\n",
    ")\n",
    "\n",
    "print(f\"   ‚ñ∂ X_train7 shape: {X_train7.shape}\")\n",
    "print(f\"   ‚ñ∂ y_train7 shape: {y_train7.shape}\")\n",
    "print(f\"   ‚ñ∂ X_val7   shape: {X_val7.shape}\")\n",
    "print(f\"   ‚ñ∂ y_val7   shape: {y_val7.shape}\")\n",
    "print(f\"   ‚ñ∂ X_test7  shape: {X_test7.shape}\")\n",
    "print(f\"   ‚ñ∂ y_test7  shape: {y_test7.shape}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:03:03.036042Z",
     "iopub.status.busy": "2025-06-07T07:03:03.035727Z",
     "iopub.status.idle": "2025-06-07T07:03:53.360991Z",
     "shell.execute_reply": "2025-06-07T07:03:53.360357Z",
     "shell.execute_reply.started": "2025-06-07T07:03:03.036023Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ### Instantiate LSTM Model (Week‚ÄêAhead)\n",
    "\n",
    "lstm_config_week = {\n",
    "    \"seq_length\": seq_len,\n",
    "    \"n_features\": len(feature_cols7),\n",
    "    \"hidden_units\": CONFIG['hidden_units'],\n",
    "    \"dropout\": CONFIG['dropout'],\n",
    "    \"learning_rate\": CONFIG['learning_rate'],\n",
    "    \"use_embedding\": CONFIG['use_embedding'],\n",
    "    \"embedding_dim\": CONFIG['embedding_dim'],\n",
    "    \"scale_features\": CONFIG['scale_features'],\n",
    "    \"scale_target\": CONFIG['scale_target'],\n",
    "    \"random_state\": CONFIG['seed']\n",
    "}\n",
    "\n",
    "print(\"üöÄ Building Week‚ÄêAhead LSTMForecaster‚Ä¶\")\n",
    "model_week = LSTMForecaster(**lstm_config_week)\n",
    "\n",
    "# Build explicitly to inspect summary\n",
    "model_week.build_model(\n",
    "    n_features=len(feature_cols7),\n",
    "    n_households=df_sel['household_code'].nunique()\n",
    ")\n",
    "model_week.get_model_summary()\n",
    "\n",
    "# ### Train LSTM Model (Week‚ÄêAhead)\n",
    "\n",
    "\n",
    "print(\"\\nüèãÔ∏è Training Week‚ÄêAhead LSTM model‚Ä¶\")\n",
    "history_week = model_week.fit(\n",
    "    X_train7, y_train7,\n",
    "    X_val=X_val7, y_val=y_val7,\n",
    "    household_train=hh_train7, household_val=hh_val7,\n",
    "    epochs=CONFIG['epochs'],\n",
    "    batch_size=CONFIG['batch_size'],\n",
    "    early_stopping=True,\n",
    "    patience=CONFIG['early_stopping_patience'],\n",
    "    verbose=2\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:03:53.362193Z",
     "iopub.status.busy": "2025-06-07T07:03:53.361996Z",
     "iopub.status.idle": "2025-06-07T07:04:04.965586Z",
     "shell.execute_reply": "2025-06-07T07:04:04.964771Z",
     "shell.execute_reply.started": "2025-06-07T07:03:53.362177Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ### Predict & Evaluate (Week‚ÄêAhead)\n",
    "\n",
    "#%%\n",
    "y_train_pred_week = model_week.predict(X_train7, hh_train7)\n",
    "y_val_pred_week   = model_week.predict(X_val7,   hh_val7)\n",
    "y_test_pred_week  = model_week.predict(X_test7,  hh_test7)\n",
    "\n",
    "metrics_train_week = model_week.evaluate(X_train7, y_train7, hh_train7)\n",
    "metrics_val_week   = model_week.evaluate(X_val7,   y_val7,   hh_val7)\n",
    "metrics_test_week  = model_week.evaluate(X_test7,  y_test7,  hh_test7)\n",
    "\n",
    "print(\"\\nüìä OVERALL Week‚ÄêAhead LSTM Evaluation\")\n",
    "print(\"------------------------------------------------\")\n",
    "print_split_summary(\"Train7\", y_train7, y_train_pred_week)\n",
    "print_split_summary(\"Val7\",   y_val7,   y_val_pred_week)\n",
    "print_split_summary(\"Test7\",  y_test7,  y_test_pred_week)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:04:04.968203Z",
     "iopub.status.busy": "2025-06-07T07:04:04.967940Z",
     "iopub.status.idle": "2025-06-07T07:04:05.895226Z",
     "shell.execute_reply": "2025-06-07T07:04:05.894275Z",
     "shell.execute_reply.started": "2025-06-07T07:04:04.968182Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "# ### Plot Actual vs Predicted (Week‚ÄêAhead) for Sample Households\n",
    "\n",
    "#%%\n",
    "unique_hh_week = np.unique(hh_test7)\n",
    "sample_hhs_week = np.random.choice(unique_hh_week, size=3, replace=False)\n",
    "\n",
    "for hh in sample_hhs_week:\n",
    "    hh_mask = (hh_test7 == hh)\n",
    "    dates = date_test7[hh_mask]\n",
    "    y_true_hh = y_test7[hh_mask]\n",
    "    y_pred_hh = y_test_pred_week[hh_mask]\n",
    "\n",
    "    plt.figure(figsize=(10, 3))\n",
    "    plt.plot(dates, y_true_hh, label=\"Actual\", marker='o', linestyle='-')\n",
    "    plt.plot(dates, y_pred_hh, label=\"Predicted\", marker='x', linestyle='--')\n",
    "    plt.title(f\"Household {hh}: Actual vs Predicted (Week‚ÄêAhead)\")\n",
    "    plt.xlabel(\"Date\")\n",
    "    plt.ylabel(\"7‚ÄêDay Avg kWh\")\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "# ### Plot Residuals vs Time (Week‚ÄêAhead)\n",
    "\n",
    "#%%\n",
    "residuals_week = y_test7 - y_test_pred_week\n",
    "plt.figure(figsize=(10, 3))\n",
    "plt.scatter(date_test7, residuals_week, alpha=0.3)\n",
    "plt.hlines(0, xmin=date_test7.min(), xmax=date_test7.max(), colors=\"red\")\n",
    "plt.title(\"Residuals vs Time (Week‚ÄêAhead Test)\")\n",
    "plt.xlabel(\"Date\")\n",
    "plt.ylabel(\"Residual (Actual ‚àí Predicted)\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-06-07T07:00:36.716741Z",
     "iopub.status.busy": "2025-06-07T07:00:36.716240Z",
     "iopub.status.idle": "2025-06-07T07:00:36.734751Z",
     "shell.execute_reply": "2025-06-07T07:00:36.733976Z",
     "shell.execute_reply.started": "2025-06-07T07:00:36.716706Z"
    },
    "trusted": true
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "src/utils/sequence_builder.py\n",
    "\n",
    "Utility functions to convert a feature‚Äêengineered DataFrame into sliding‚Äêwindow\n",
    "(‚Äúsequence‚Äù) inputs for LSTM training. Supports both global (all households)\n",
    "and per‚Äêhousehold sequence construction. Handles optional household_code alignment,\n",
    "and can optionally return the target dates for plotting.\n",
    "\n",
    "Author: Shruthi Simha Chippagiri\n",
    "Date: 2025\n",
    "\"\"\"\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def build_sequences(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    target_col: str,\n",
    "    seq_len: int,\n",
    "    group_col: str = \"LCLid\",\n",
    "    include_household: bool = False,\n",
    "    household_col: str = \"household_code\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Build sliding‚Äêwindow sequences for LSTM input from a long DataFrame sorted by group and time.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pd.DataFrame\n",
    "        DataFrame containing time series data. Must be sorted by [group_col, date_col].\n",
    "    feature_cols : list of str\n",
    "        List of feature column names (e.g., lag_*, weather, calendar flags, etc.).\n",
    "    target_col : str\n",
    "        Name of the target column (e.g., 'label_1' or 'label_7').\n",
    "    seq_len : int\n",
    "        Number of consecutive time steps per sequence (e.g., 14).\n",
    "    group_col : str, default \"LCLid\"\n",
    "        Column name indicating household or group identifier.\n",
    "    include_household : bool, default False\n",
    "        If True, also return an array of household codes aligned to each sequence.\n",
    "    household_col : str, default \"household_code\"\n",
    "        Column name containing integer‚Äêcoded household IDs (0..n_households-1).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    X : np.ndarray, shape (N_samples, seq_len, n_features)\n",
    "        Sequence input array.\n",
    "    y : np.ndarray, shape (N_samples,)\n",
    "        Target values corresponding to each sequence.\n",
    "    hh_codes : np.ndarray, shape (N_samples,), optional\n",
    "        Household codes aligned to each sequence (only if include_household=True).\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    - The DataFrame df should be sorted first by group_col, then by date (chronological).\n",
    "    - This function will only build sequences where all seq_len steps and the target step exist.\n",
    "    - If any NaNs appear in the features or target within the window, that sequence is skipped.\n",
    "    - If include_household=True, hh_codes[i] will be the household_code at the final time step of the i-th sequence.\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    hh_list = []\n",
    "\n",
    "    for hh, group_df in df.groupby(group_col):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "\n",
    "        if include_household:\n",
    "            hh_series = group_df[household_col].values\n",
    "\n",
    "        features_array = group_df[feature_cols].values\n",
    "        target_array = group_df[target_col].values\n",
    "\n",
    "        for i in range(len(group_df) - seq_len):\n",
    "            window_feats = features_array[i : i + seq_len]\n",
    "            window_target = target_array[i + seq_len]\n",
    "\n",
    "            if np.isnan(window_feats).any() or np.isnan(window_target):\n",
    "                continue\n",
    "\n",
    "            X_list.append(window_feats)\n",
    "            y_list.append(window_target)\n",
    "            if include_household:\n",
    "                hh_list.append(hh_series[i + seq_len])\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=float)\n",
    "\n",
    "    if include_household:\n",
    "        hh_codes = np.array(hh_list, dtype=int)\n",
    "        return X, y, hh_codes\n",
    "\n",
    "    return X, y\n",
    "\n",
    "\n",
    "def build_global_sequences(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    target_col: str,\n",
    "    seq_len: int,\n",
    "    group_col: str = \"LCLid\",\n",
    "    household_col: str = \"household_code\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Convenience function to build sequences for train/val/test splits all at once.\n",
    "    Returns X_train, y_train, hh_train, X_val, y_val, hh_val, X_test, y_test, hh_test.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    train_df, val_df, test_df : pd.DataFrame\n",
    "        Pre‚Äêsplit DataFrames. Each should be sorted by [group_col, date].\n",
    "    feature_cols : list of str\n",
    "        List of feature column names.\n",
    "    target_col : str\n",
    "        Name of the target column.\n",
    "    seq_len : int\n",
    "        Sequence length.\n",
    "    group_col : str, default \"LCLid\"\n",
    "        Household identifier column.\n",
    "    household_col : str, default \"household_code\"\n",
    "        Integer‚Äêcoded household ID column.\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    (X_train, y_train, hh_train,\n",
    "     X_val,   y_val,   hh_val,\n",
    "     X_test,  y_test,  hh_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train, hh_train = build_sequences(\n",
    "        train_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col\n",
    "    )\n",
    "    X_val, y_val, hh_val = build_sequences(\n",
    "        val_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col\n",
    "    )\n",
    "    X_test, y_test, hh_test = build_sequences(\n",
    "        test_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col\n",
    "    )\n",
    "\n",
    "    return (X_train, y_train, hh_train,\n",
    "            X_val,   y_val,   hh_val,\n",
    "            X_test,  y_test,  hh_test)\n",
    "\n",
    "\n",
    "def build_sequences_with_dates(\n",
    "    df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    target_col: str,\n",
    "    seq_len: int,\n",
    "    group_col: str = \"LCLid\",\n",
    "    include_household: bool = False,\n",
    "    household_col: str = \"household_code\",\n",
    "    date_col: str = \"day\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Like build_sequences, but also returns the target date for each window.\n",
    "\n",
    "    Returns:\n",
    "      X : np.ndarray (N, seq_len, n_features)\n",
    "      y : np.ndarray (N,)\n",
    "      hh_codes : np.ndarray (N,)  # only if include_household=True\n",
    "      dates  : np.ndarray (N,)    # the 'day' corresponding to the target for each sequence\n",
    "    \"\"\"\n",
    "    X_list = []\n",
    "    y_list = []\n",
    "    hh_list = []\n",
    "    date_list = []\n",
    "\n",
    "    for hh, group_df in df.groupby(group_col):\n",
    "        group_df = group_df.reset_index(drop=True)\n",
    "\n",
    "        if include_household:\n",
    "            hh_series = group_df[household_col].values\n",
    "\n",
    "        features_array = group_df[feature_cols].values\n",
    "        target_array = group_df[target_col].values\n",
    "        date_array = pd.to_datetime(group_df[date_col]).values\n",
    "\n",
    "        for i in range(len(group_df) - seq_len):\n",
    "            window_feats = features_array[i : i + seq_len]\n",
    "            window_target = target_array[i + seq_len]\n",
    "            window_date = date_array[i + seq_len]\n",
    "\n",
    "            if np.isnan(window_feats).any() or np.isnan(window_target):\n",
    "                continue\n",
    "\n",
    "            X_list.append(window_feats)\n",
    "            y_list.append(window_target)\n",
    "            date_list.append(window_date)\n",
    "\n",
    "            if include_household:\n",
    "                hh_list.append(hh_series[i + seq_len])\n",
    "\n",
    "    X = np.stack(X_list, axis=0)\n",
    "    y = np.array(y_list, dtype=float)\n",
    "    dates = np.array(date_list, dtype=\"datetime64[ns]\")\n",
    "\n",
    "    if include_household:\n",
    "        hh_codes = np.array(hh_list, dtype=int)\n",
    "        return X, y, hh_codes, dates\n",
    "\n",
    "    return X, y, dates\n",
    "\n",
    "\n",
    "def build_global_sequences_with_dates(\n",
    "    train_df: pd.DataFrame,\n",
    "    val_df: pd.DataFrame,\n",
    "    test_df: pd.DataFrame,\n",
    "    feature_cols: list,\n",
    "    target_col: str,\n",
    "    seq_len: int,\n",
    "    group_col: str = \"LCLid\",\n",
    "    household_col: str = \"household_code\",\n",
    "    date_col: str = \"day\"\n",
    "):\n",
    "    \"\"\"\n",
    "    Calls build_sequences_with_dates on train/val/test and returns\n",
    "    (X_train, y_train, hh_train, date_train,\n",
    "     X_val,   y_val,   hh_val,   date_val,\n",
    "     X_test,  y_test,  hh_test,  date_test)\n",
    "    \"\"\"\n",
    "    X_train, y_train, hh_train, date_train = build_sequences_with_dates(\n",
    "        train_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col,\n",
    "        date_col=date_col\n",
    "    )\n",
    "    X_val, y_val, hh_val, date_val = build_sequences_with_dates(\n",
    "        val_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col,\n",
    "        date_col=date_col\n",
    "    )\n",
    "    X_test, y_test, hh_test, date_test = build_sequences_with_dates(\n",
    "        test_df, feature_cols, target_col, seq_len,\n",
    "        group_col=group_col,\n",
    "        include_household=True,\n",
    "        household_col=household_col,\n",
    "        date_col=date_col\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        X_train, y_train, hh_train, date_train,\n",
    "        X_val,   y_val,   hh_val,   date_val,\n",
    "        X_test,  y_test,  hh_test,  date_test\n",
    "    )\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [
    {
     "datasetId": 4021,
     "sourceId": 3684057,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7235302,
     "sourceId": 11536719,
     "sourceType": "datasetVersion"
    },
    {
     "datasetId": 7556281,
     "sourceId": 12085787,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31040,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
