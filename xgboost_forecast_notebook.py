"""
ğŸ“ˆ XGBOOST FORECASTING NOTEBOOK - ENHANCED EDITION
=================================================

Comprehensive notebook-style implementation of XGBoost for day-ahead and week-ahead
forecasting of smart meter data using the enhanced clean pipeline architecture.

ğŸ”§ ENHANCED FEATURES:
- âœ… Clean separation of concerns (features â†’ splitting â†’ modeling)
- âœ… Optuna hyperparameter optimization 
- âœ… GPU/CPU resource optimization
- âœ… Log transform option for relative error modeling
- âœ… Comprehensive evaluation and visualization
- âœ… Leakage-safe feature engineering

Author: Shruthi Simha Chippagiri
Date: 2025
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import warnings
warnings.filterwarnings('ignore')

# Import our enhanced modules
from data.data_loader import load_all_raw_data
from data.data_cleaner import clean_and_merge_all_data     # or clean_all_data, whichever you use
from features.feature_pipeline import create_comprehensive_features
from features.splitters import prepare_forecasting_data, prepare_weekahead_data
from models.xgboost_forecasting import (
    train_and_evaluate_dayahead,
    train_and_evaluate_weekahead,
    prepare_xgboost_data,
    predict_xgboost
)
from evaluation.forecast_evaluation import (
    compute_regression_metrics,
    print_regression_results,
    evaluate_forecast_model,
    compare_forecast_models,
    evaluate_peak_performance
)

# Configuration
CONFIG = {
    'data_path': 'data',
    'test_days': 90,
    'val_days': 30,
    'sample_household': None,  # Will auto-select first available
    'save_plots': True,
    'plot_dir': 'plots/xgboost_notebook/',
    'use_gpu': False,  # Set to True if you have GPU
    'log_transform': True,  # Use log transform for relative error modeling
    'n_trials': 60,  # Optuna optimization trials
    'seed': 42
}

print("ğŸš€ ENHANCED XGBOOST FORECASTING WITH CLEAN PIPELINE")
print("=" * 60)
print("ğŸ“Š NEW CLEAN ARCHITECTURE:")
print("   1ï¸âƒ£ Feature Engineering (leakage-safe)")
print("   2ï¸âƒ£ Data Splitting (chronological)")
print("   3ï¸âƒ£ Model Building (with Optuna)")
print("   4ï¸âƒ£ Evaluation & Visualization")
print("=" * 60)
print("âœ… ENHANCED FEATURES:")
print("   ğŸ” Optuna hyperparameter optimization")
print("   âš¡ GPU acceleration support" if CONFIG['use_gpu'] else "   ğŸ’» CPU processing")
print("   ğŸ“ˆ Log transform for relative errors" if CONFIG['log_transform'] else "   ğŸ“Š Linear scale modeling")
print("   ğŸ”’ Automatic leakage prevention")
print("   ğŸ“Š Comprehensive model evaluation")
print("=" * 60)

#%% ================================================================
# STEP 1: DATA LOADING AND FEATURE ENGINEERING
#%% ================================================================

print("\n1ï¸âƒ£ STEP 1: DATA LOADING AND FEATURE ENGINEERING")
print("-" * 50)

# Load and clean data
print("ğŸ“‚ Loading raw smart meter data...")
raw_data = load_all_raw_data(CONFIG['data_path'])

print("ğŸ§¹ Cleaning data...")
cleaned_data = clean_and_merge_all_data(raw_data)   # or clean_all_data(raw_data), depending on your naming

print("ğŸ”§ Creating comprehensive leakage-safe features...")
df_features = create_comprehensive_features(cleaned_data)

print(f"âœ… Feature engineering completed:")
print(f"   ğŸ“Š Total samples: {len(df_features):,}")
print(f"   ğŸ“… Date range: {df_features['day'].min()} to {df_features['day'].max()}")
print(f"   ğŸ  Households: {df_features['LCLid'].nunique()}")
print(f"   ğŸ”§ Features created: {len(df_features.columns)} total columns")

#%% ================================================================
# STEP 2: DATA SPLITTING (CHRONOLOGICAL & LEAKAGE-SAFE)
#%% ================================================================

print("\n2ï¸âƒ£ STEP 2: DATA SPLITTING")
print("-" * 30)

print("ğŸ“Š Preparing day-ahead forecasting data...")
# Note: We no longer pass `household_meta` hereâ€”static columns (Acorn, stdorToU, etc.) have
# already been merged into df_features upstream.
train_df, val_df, test_df, feature_cols, target_col, feature_groups = prepare_forecasting_data(
    df_features,
    target_col="total_kwh", 
    test_days=CONFIG['test_days'], 
    val_days=CONFIG['val_days']
)

print(f"âœ… Day-ahead data preparation:")
print(f"   ğŸ“ˆ Training samples: {len(train_df):,}")
print(f"   ğŸ” Validation samples: {len(val_df):,}")
print(f"   ğŸ¯ Test samples: {len(test_df):,}")
print(f"   ğŸ”§ Features: {len(feature_cols)}")
print(f"   ğŸ¯ Target: {target_col}")

print("\nğŸ“… Preparing week-ahead forecasting data...")
# Again, no `household_meta` argument
train_df7, val_df7, test_df7, feature_cols7, target7, feature_groups7 = prepare_weekahead_data(
    raw_data,
    df_features,
    test_days=CONFIG['test_days'],
    val_days=CONFIG['val_days']
)

print(f"âœ… Week-ahead data preparation:")
print(f"   ğŸ“ˆ Training samples: {len(train_df7):,}")
print(f"   ğŸ” Validation samples: {len(val_df7):,}")
print(f"   ğŸ¯ Test samples: {len(test_df7):,}")
print(f"   ğŸ”§ Features: {len(feature_cols7)}")
print(f"   ğŸ¯ Target: {target7}")

# Show feature breakdown
print(f"\nğŸ“Š Feature groups breakdown:")
for group_name, group_features in feature_groups.items():
    print(f"   {group_name}: {len(group_features)} features")

#%% ================================================================
# STEP 3: HOUSEHOLD SELECTION
#%% ================================================================

print("\n3ï¸âƒ£ STEP 3: HOUSEHOLD SELECTION")
print("-" * 35)

# Select household for analysis
available_households = train_df['LCLid'].unique()
selected_household = CONFIG['sample_household'] or available_households[0]

print(f"ğŸ  Available households: {len(available_households)}")
print(f"ğŸ  Selected household: {selected_household}")

# Get household statistics using the correct target column (label_1, not total_kwh)
household_train = train_df[train_df['LCLid'] == selected_household]
print(f"ğŸ“Š Household consumption profile:")
print(f"   ğŸ“ˆ Average: {household_train[target_col].mean():.2f} kWh/day")
print(f"   ğŸ“Š Range: {household_train[target_col].min():.1f} - {household_train[target_col].max():.1f} kWh/day")
print(f"   ğŸ“ˆ Std dev: {household_train[target_col].std():.2f} kWh/day")

#%% ================================================================
# STEP 4: DAY-AHEAD FORECASTING WITH ENHANCED XGBOOST
#%% ================================================================

print("\n4ï¸âƒ£ STEP 4: DAY-AHEAD FORECASTING")
print("-" * 40)

print("ğŸš€ Starting enhanced day-ahead forecasting pipeline...")
print(f"   ğŸ” Optuna trials: {CONFIG['n_trials']}")
print(f"   âš¡ GPU acceleration: {CONFIG['use_gpu']}")
print(f"   ğŸ“ˆ Log transform: {CONFIG['log_transform']}")

# Filter data for selected household
household_train = train_df[train_df['LCLid'] == selected_household].copy()
household_val = val_df[val_df['LCLid'] == selected_household].copy()
household_test = test_df[test_df['LCLid'] == selected_household].copy()

print(f"ğŸ“Š Household data: {len(household_train)} train, {len(household_val)} val, {len(household_test)} test")

# Run enhanced day-ahead forecasting
day_ahead_results = train_and_evaluate_dayahead(
    household_train,
    household_val, 
    household_test,
    feature_cols,
    target_col=target_col,
    use_gpu=CONFIG['use_gpu'],
    n_trials=CONFIG['n_trials'],
    log_transform=CONFIG['log_transform']
)

print("âœ… Day-ahead forecasting completed!")


from evaluation.forecast_evaluation import compute_regression_metrics

y_true_day = day_ahead_results['actuals']['test']
y_pred_day = day_ahead_results['predictions']['test']
day_metrics = compute_regression_metrics(y_true_day, y_pred_day)

dates_day = household_test['day'].values

print(f"\nğŸ“ˆ DAY-AHEAD RESULTS:")
print_regression_results(day_metrics, "Test Set")

#%% ================================================================
# STEP 5: WEEK-AHEAD FORECASTING
#%% ================================================================

print("\n5ï¸âƒ£ STEP 5: WEEK-AHEAD FORECASTING")
print("-" * 40)

print("ğŸš€ Starting enhanced week-ahead forecasting pipeline...")

# Filter week-ahead data for selected household
household_train7 = train_df7[train_df7['LCLid'] == selected_household].copy()
household_val7 = val_df7[val_df7['LCLid'] == selected_household].copy()
household_test7 = test_df7[test_df7['LCLid'] == selected_household].copy()

print(f"ğŸ“Š Week-ahead data: {len(household_train7)} train, {len(household_val7)} val, {len(household_test7)} test")

# Run enhanced week-ahead forecasting
week_ahead_results = train_and_evaluate_weekahead(
    household_train7,
    household_val7,
    household_test7,
    feature_cols7,
    target_col=target7,
    use_gpu=CONFIG['use_gpu'],
    n_trials=CONFIG['n_trials'],
    log_transform=CONFIG['log_transform']
)

print("âœ… Week-ahead forecasting completed!")

# Extract key results
y_true_week = week_ahead_results['actuals']['test']
y_pred_week = week_ahead_results['predictions']['test']
week_metrics = compute_regression_metrics(y_true_week, y_pred_week)

print(f"\nğŸ“… WEEK-AHEAD RESULTS:")
print_regression_results(week_metrics, "Test Set")

#%% ================================================================
# STEP 6: MODEL COMPARISON AND ANALYSIS
#%% ================================================================

print("\n6ï¸âƒ£ STEP 6: MODEL COMPARISON AND ANALYSIS")
print("-" * 45)

# Compare models
model_results = {
    'Day-Ahead XGBoost': day_ahead_results,
    'Week-Ahead XGBoost': week_ahead_results
}

print("ğŸ“Š Comparing forecasting horizons...")
comparison_df = compare_forecast_models(model_results)

# Performance summary
print(f"\nğŸ“ˆ PERFORMANCE SUMMARY:")
print(f"   Day-ahead MAPE: {day_metrics['MAPE']:.2f}%")
print(f"   Week-ahead MAPE: {week_metrics['MAPE']:.2f}%")
print(f"   Day-ahead RÂ²: {day_metrics['R2']:.3f}")
print(f"   Week-ahead RÂ²: {week_metrics['R2']:.3f}")

# Feature importance analysis
print(f"\nğŸ¯ TOP 10 IMPORTANT FEATURES (Day-Ahead):")
top_features = day_ahead_results['feature_importance'].head(10)
for idx, row in top_features.iterrows():
    print(f"   {idx+1:2d}. {row['feature']}: {row['importance']:.4f}")

#%% ================================================================
# STEP 7: PEAK PERFORMANCE ANALYSIS
#%% ================================================================

print("\n7ï¸âƒ£ STEP 7: PEAK PERFORMANCE ANALYSIS")
print("-" * 45)

# Analyze peak consumption forecasting
day_peak_analysis = evaluate_peak_performance(y_true_day, y_pred_day, 90)
week_peak_analysis = evaluate_peak_performance(y_true_week, y_pred_week, 90)


